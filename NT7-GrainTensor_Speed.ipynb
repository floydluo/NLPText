{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.timedelta(0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "a = datetime.now() \n",
    "a\n",
    "a-a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlptext.token import Token\n",
    "from nlptext.utils.grain import generate_batch, getTokenBatchInfo\n",
    "\n",
    "from nlptext.base import BasicObject\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "CHANNEL_SETTINGS_TEMPLATE = {\n",
    "    # CTX_IND\n",
    "    'token':   {'use': True, 'Max_Ngram': 1,},\n",
    "    'char':    {'use': True,'Max_Ngram': 1, 'end_grain': False},\n",
    "    'basic':   {'use': True,'Max_Ngram': 2, 'end_grain': False},\n",
    "    'medical': {'use': True,'Max_Ngram': 2, 'end_grain': False},\n",
    "    'radical': {'use': True,'Max_Ngram': 2, 'end_grain': False},\n",
    "    'subcomp': {'use': True,'Max_Ngram': 3, 'end_grain': True},\n",
    "    'stroke':  {'use': True,'Max_Ngram': 5, 'end_grain': True},\n",
    "    # CTX_DEP\n",
    "    'pos':     {'use': False,'Max_Ngram': 1, 'end_grain': False, 'tagScheme':   'BIO',},\n",
    "    # ANNO\n",
    "    'annoR':   {'use': False,'Max_Ngram': 1, 'end_grain': False, 'tagScheme':   'BIO',},\n",
    "    'annoE':   {'use': False,'Max_Ngram': 1, 'end_grain': False, 'tagScheme':   'BIO',},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORPUS\tread from pickle file : channel/WikiTotal/word/Token447170/Pyramid/CORPUS.p\n",
      "CORPUS\tthe length of it is   : 1\n",
      "FOLDER\tread from pickle file : channel/WikiTotal/word/Token447170/Pyramid/FOLDER.p\n",
      "FOLDER\tthe length of it is   : 1\n",
      "TEXT\tread from pickle file : channel/WikiTotal/word/Token447170/Pyramid/TEXT.p\n",
      "TEXT\tthe length of it is   : 4717592\n",
      "SENT\tread from pickle file : channel/WikiTotal/word/Token447170/Pyramid/SENT.p\n",
      "SENT\tthe length of it is   : 11199643\n",
      "TOKEN\tread from pickle file : channel/WikiTotal/word/Token447170/Pyramid/TOKEN.p\n",
      "TOKEN\tthe length of it is   : 257789077\n",
      "**************************************** \n",
      "\n",
      "token\tread from pickle file : channel/WikiTotal/word/Token447170/GrainUnique/token.p\n",
      "token\tthe length of it is   : 447170\n",
      "**************************************** \n",
      "\n",
      "Deal with the Channel: token\n",
      "Current Channel is        \t token\n",
      "Current Channel Max_Ngram \t 1\n",
      "Deal with the Channel: char\n",
      "Current Channel is        \t char\n",
      "Current Channel Max_Ngram \t 1\n",
      "Deal with the Channel: basic\n",
      "Current Channel is        \t basic\n",
      "Current Channel Max_Ngram \t 2\n",
      "Deal with the Channel: medical\n",
      "Current Channel is        \t medical\n",
      "Current Channel Max_Ngram \t 2\n",
      "Deal with the Channel: radical\n",
      "Current Channel is        \t radical\n",
      "Current Channel Max_Ngram \t 2\n",
      "Deal with the Channel: subcomp\n",
      "Current Channel is        \t subcomp\n",
      "Current Channel Max_Ngram \t 3\n",
      "Deal with the Channel: stroke\n",
      "Current Channel is        \t stroke\n",
      "Current Channel Max_Ngram \t 5\n"
     ]
    }
   ],
   "source": [
    "BOB = 'channel/WikiTotal/word/Token447170/Pyramid'\n",
    "LGU = 'channel/WikiTotal/word/Token447170/GrainUnique'\n",
    "BasicObject.INIT_FROM_PICKLE(BOB, LGU)\n",
    "\n",
    "BasicObject.BUILD_GRAIN_UNI_AND_LOOKUP(CHANNEL_SETTINGS_TEMPLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token': {'Max_Ngram': 1},\n",
       " 'char': {'Max_Ngram': 1, 'end_grain': False},\n",
       " 'basic': {'Max_Ngram': 2, 'end_grain': False},\n",
       " 'medical': {'Max_Ngram': 2, 'end_grain': False},\n",
       " 'radical': {'Max_Ngram': 2, 'end_grain': False},\n",
       " 'subcomp': {'Max_Ngram': 3, 'end_grain': True},\n",
       " 'stroke': {'Max_Ngram': 5, 'end_grain': True}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CH = BasicObject.CHANNEL_SETTINGS\n",
    "CH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "CH = {'token': {'Max_Ngram': 1},\n",
    " 'char': {'Max_Ngram': 1, 'end_grain': False},\n",
    " 'basic': {'Max_Ngram': 2, 'end_grain': False},\n",
    " 'medical': {'Max_Ngram': 2, 'end_grain': False},\n",
    " 'radical': {'Max_Ngram': 2, 'end_grain': False},\n",
    " 'subcomp': {'Max_Ngram': 3, 'end_grain': True},\n",
    " 'stroke': {'Max_Ngram': 5, 'end_grain': True},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_speed(total_token_num):\n",
    "    tokenIdx = list(range(total_token_num))\n",
    "    total_start = datetime.now()\n",
    "    for ch, cs in CH.items():\n",
    "        print(ch)\n",
    "        s_ch = datetime.now()\n",
    "        for i in tokenIdx:\n",
    "            tk =Token(i)\n",
    "            tk.getGrainTensor(ch, **cs, dontUseLookUp=False)\n",
    "        e_ch = datetime.now()\n",
    "        print(e_ch - s_ch)\n",
    "\n",
    "    total_end = datetime.now()\n",
    "    time = total_end- total_start\n",
    "    print('Total time:', time)\n",
    "    return time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token\n",
      "0:00:00.018738\n",
      "char\n",
      "0:00:00.025603\n",
      "basic\n",
      "0:00:00.021415\n",
      "medical\n",
      "0:00:00.021506\n",
      "radical\n",
      "0:00:00.021772\n",
      "subcomp\n",
      "0:00:00.021976\n",
      "stroke\n",
      "0:00:00.022232\n",
      "Total time: 0:00:00.153855\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "datetime.timedelta(microseconds=153855)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "total_token_num = 10000\n",
    "test_speed(total_token_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token\n",
      "0:00:00.004752\n",
      "char\n",
      "0:00:00.009822\n",
      "basic\n",
      "0:00:00.013825\n",
      "medical\n",
      "0:00:00.011008\n",
      "radical\n",
      "0:00:00.012198\n",
      "subcomp\n",
      "0:00:00.011416\n",
      "stroke\n",
      "0:00:00.011544\n",
      "Total time: 0:00:00.075161\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "datetime.timedelta(microseconds=75161)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_token_num = 5000\n",
    "test_speed(total_token_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['basic', 'medical', 'radical', 'token', 'char', 'subcomp', 'stroke']"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tk.CONTEXT_IND_CHANNELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token\n",
      "0:00:00.008516\n",
      "char\n",
      "0:00:00.020361\n",
      "basic\n",
      "0:00:00.021669\n",
      "medical\n",
      "0:00:00.020693\n",
      "radical\n",
      "0:00:00.020963\n",
      "subcomp\n",
      "0:00:00.020903\n",
      "stroke\n",
      "0:00:00.020784\n",
      "Total time: 0:00:00.135016\n"
     ]
    }
   ],
   "source": [
    "from nlptext.utils.channel import getChannelName\n",
    "\n",
    "tokenIdx = list(range(10000))\n",
    "dontUseLookUp = False\n",
    "TokenNum_Dir = False\n",
    "UNK_ID = 3\n",
    "total_start = datetime.now() # <---\n",
    "self = BasicObject\n",
    "\n",
    "for ch, cs in CH.items():\n",
    "    print(ch)\n",
    "    s_ch = datetime.now()\n",
    "    for i in tokenIdx:\n",
    "        tk =Token(i)\n",
    "        \n",
    "        if ch == 'token':\n",
    "            [tk.index], 1\n",
    "        \n",
    "        else:\n",
    "            channel_name = getChannelName(ch,**cs)\n",
    "\n",
    "            if not dontUseLookUp:\n",
    "                LOOKUP, TokenUnqiue = self.getLookUp(channel_name = channel_name, TokenNum_Dir = TokenNum_Dir)\n",
    "                LTU, DTU = TokenUnqiue\n",
    "                index = DTU.get(tk.token, UNK_ID) if TokenNum_Dir else tk.index\n",
    "                if index != UNK_ID:\n",
    "                    info = LOOKUP[index] # TODO, to do what?\n",
    "                    leng = len(info)\n",
    "\n",
    "            else:\n",
    "                LGU, DGU = self.getGrainUnique(channel_name = channel_name, TokenNum_Dir =TokenNum_Dir)\n",
    "                info = [DGU.get(i, UNK_ID) for i in tk.getChannelGrain(ch, **cs)]\n",
    "                leng = len(info)\n",
    "                \n",
    "    e_ch = datetime.now()\n",
    "    print(e_ch - s_ch)\n",
    "    \n",
    "total_end = datetime.now()\n",
    "print('Total time:', total_end- total_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "char\n",
    "0:00:00.009325\n",
    "basic\n",
    "0:00:00.008865\n",
    "medical\n",
    "0:00:00.009747\n",
    "radical\n",
    "0:00:00.007804\n",
    "subcomp\n",
    "0:00:00.007518\n",
    "stroke\n",
    "0:00:00.007718\n",
    "token\n",
    "0:00:00.003510\n",
    "Total time: 0:00:00.055877\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# total_token_num = 10000\n",
    "# result = {str(total_token_num): float(str(test_speed(total_token_num)).split(':')[-1]) for total_token_num in [1000, 2000, 4000, 8000]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls =BasicObject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.001602\n"
     ]
    }
   ],
   "source": [
    "s = datetime.now()\n",
    "for i in tokenIdx:\n",
    "    try:\n",
    "        cls.LOOKUP[TokenNum_Dir] = cls.LOOKUP[TokenNum_Dir] if TokenNum_Dir in cls.LOOKUP else {}\n",
    "    except:\n",
    "        pass\n",
    "e = datetime.now()\n",
    "print(e-s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "char\n",
      "\t 0:00:00.111344\n",
      "\t 0:00:00.002255\n",
      "\t 0:00:00.010229\n",
      "\t char 0:00:00.124160\n",
      "basic\n",
      "\t 0:00:00.091620\n",
      "\t 0:00:00.003841\n",
      "\t 0:00:00.014422\n",
      "\t basic 0:00:00.110083\n",
      "medical\n",
      "\t 0:00:00.113518\n",
      "\t 0:00:00.001496\n",
      "\t 0:00:00.010786\n",
      "\t medical 0:00:00.125986\n",
      "radical\n",
      "\t 0:00:00.112859\n",
      "\t 0:00:00.002941\n",
      "\t 0:00:00.010814\n",
      "\t radical 0:00:00.126755\n",
      "subcomp\n",
      "\t 0:00:00.099234\n",
      "\t 0:00:00.001936\n",
      "\t 0:00:00.021576\n",
      "\t subcomp 0:00:00.122867\n",
      "stroke\n",
      "\t 0:00:00.102684\n",
      "\t 0:00:00.002610\n",
      "\t 0:00:00.063201\n",
      "\t stroke 0:00:00.168635\n",
      "\t\t 0:00:00.779424\n",
      "0:00:00.903077\n",
      "char\n",
      "\t 0:00:00.101039\n",
      "\t 0:00:00.002171\n",
      "\t 0:00:00.011241\n",
      "\t char 0:00:00.114557\n",
      "basic\n",
      "\t 0:00:00.096462\n",
      "\t 0:00:00.001898\n",
      "\t 0:00:00.009872\n",
      "\t basic 0:00:00.108328\n",
      "medical\n",
      "\t 0:00:00.118875\n",
      "\t 0:00:00.003361\n",
      "\t 0:00:00.019948\n",
      "\t medical 0:00:00.142637\n",
      "radical\n",
      "\t 0:00:00.123382\n",
      "\t 0:00:00.002507\n",
      "\t 0:00:00.010382\n",
      "\t radical 0:00:00.136382\n",
      "subcomp\n",
      "\t 0:00:00.117160\n",
      "\t 0:00:00.002497\n",
      "\t 0:00:00.021940\n",
      "\t subcomp 0:00:00.141803\n",
      "stroke\n",
      "\t 0:00:00.121830\n",
      "\t 0:00:00.002785\n",
      "\t 0:00:00.055707\n",
      "\t stroke 0:00:00.180464\n",
      "\t\t 0:00:00.824922\n",
      "0:00:00.968170\n",
      "char\n",
      "\t 0:00:00.127976\n",
      "\t 0:00:00.002718\n",
      "\t 0:00:00.012723\n",
      "\t char 0:00:00.143541\n",
      "basic\n",
      "\t 0:00:00.121799\n",
      "\t 0:00:00.002737\n",
      "\t 0:00:00.010377\n",
      "\t basic 0:00:00.135038\n",
      "medical\n",
      "\t 0:00:00.116469\n",
      "\t 0:00:00.003173\n",
      "\t 0:00:00.014379\n",
      "\t medical 0:00:00.134187\n",
      "radical\n",
      "\t 0:00:00.124280\n",
      "\t 0:00:00.004183\n",
      "\t 0:00:00.011367\n",
      "\t radical 0:00:00.140544\n",
      "subcomp\n",
      "\t 0:00:00.121792\n",
      "\t 0:00:00.002053\n",
      "\t 0:00:00.020867\n",
      "\t subcomp 0:00:00.144837\n",
      "stroke\n",
      "\t 0:00:00.130123\n",
      "\t 0:00:00.003591\n",
      "\t 0:00:00.056203\n",
      "\t stroke 0:00:00.190491\n",
      "\t\t 0:00:00.889710\n",
      "0:00:01.014416\n",
      "char\n",
      "\t 0:00:00.114187\n",
      "\t 0:00:00.003604\n",
      "\t 0:00:00.010631\n",
      "\t char 0:00:00.128578\n",
      "basic\n",
      "\t 0:00:00.111801\n",
      "\t 0:00:00.002218\n",
      "\t 0:00:00.010694\n",
      "\t basic 0:00:00.124849\n",
      "medical\n",
      "\t 0:00:00.103545\n",
      "\t 0:00:00.002927\n",
      "\t 0:00:00.010748\n",
      "\t medical 0:00:00.117373\n",
      "radical\n",
      "\t 0:00:00.100578\n",
      "\t 0:00:00.002510\n",
      "\t 0:00:00.010551\n",
      "\t radical 0:00:00.113779\n",
      "subcomp\n",
      "\t 0:00:00.112804\n",
      "\t 0:00:00.002938\n",
      "\t 0:00:00.022727\n",
      "\t subcomp 0:00:00.138646\n",
      "stroke\n",
      "\t 0:00:00.148072\n",
      "\t 0:00:00.004215\n",
      "\t 0:00:00.084518\n",
      "\t stroke 0:00:00.237193\n",
      "\t\t 0:00:00.861620\n",
      "0:00:00.985566\n",
      "char\n",
      "\t 0:00:00.107636\n",
      "\t 0:00:00.001537\n",
      "\t 0:00:00.010068\n",
      "\t char 0:00:00.119543\n",
      "basic\n",
      "\t 0:00:00.925019\n",
      "\t 0:00:00.002237\n",
      "\t 0:00:00.009801\n",
      "\t basic 0:00:00.937389\n",
      "medical\n",
      "\t 0:00:00.109044\n",
      "\t 0:00:00.002563\n",
      "\t 0:00:00.011866\n",
      "\t medical 0:00:00.123600\n",
      "radical\n",
      "\t 0:00:00.119002\n",
      "\t 0:00:00.002643\n",
      "\t 0:00:00.013132\n",
      "\t radical 0:00:00.134919\n",
      "subcomp\n",
      "\t 0:00:00.102524\n",
      "\t 0:00:00.002622\n",
      "\t 0:00:00.023250\n",
      "\t subcomp 0:00:00.128550\n",
      "stroke\n",
      "\t 0:00:00.098281\n",
      "\t 0:00:00.002417\n",
      "\t 0:00:00.050456\n",
      "\t stroke 0:00:00.151288\n",
      "\t\t 0:00:01.596266\n",
      "0:00:01.732500\n",
      "char\n",
      "\t 0:00:00.114309\n",
      "\t 0:00:00.002405\n",
      "\t 0:00:00.012429\n",
      "\t char 0:00:00.129516\n",
      "basic\n",
      "\t 0:00:00.113941\n",
      "\t 0:00:00.002274\n",
      "\t 0:00:00.010654\n",
      "\t basic 0:00:00.126981\n",
      "medical\n",
      "\t 0:00:00.117903\n",
      "\t 0:00:00.001571\n",
      "\t 0:00:00.011839\n",
      "\t medical 0:00:00.131490\n",
      "radical\n",
      "\t 0:00:00.108859\n",
      "\t 0:00:00.002076\n",
      "\t 0:00:00.010669\n",
      "\t radical 0:00:00.121712\n",
      "subcomp\n",
      "\t 0:00:00.116861\n",
      "\t 0:00:00.001929\n",
      "\t 0:00:00.021878\n",
      "\t subcomp 0:00:00.141011\n",
      "stroke\n",
      "\t 0:00:00.103592\n",
      "\t 0:00:00.001417\n",
      "\t 0:00:00.052344\n",
      "\t stroke 0:00:00.157448\n",
      "\t\t 0:00:00.809529\n",
      "0:00:00.937652\n",
      "char\n",
      "\t 0:00:00.108548\n",
      "\t 0:00:00.002290\n",
      "\t 0:00:00.010519\n",
      "\t char 0:00:00.121472\n",
      "basic\n",
      "\t 0:00:00.114979\n",
      "\t 0:00:00.002919\n",
      "\t 0:00:00.010673\n",
      "\t basic 0:00:00.128727\n",
      "medical\n",
      "\t 0:00:00.114425\n",
      "\t 0:00:00.002408\n",
      "\t 0:00:00.010562\n",
      "\t medical 0:00:00.127505\n",
      "radical\n",
      "\t 0:00:00.104792\n",
      "\t 0:00:00.002483\n",
      "\t 0:00:00.010824\n",
      "\t radical 0:00:00.118241\n",
      "subcomp\n",
      "\t 0:00:00.097671\n",
      "\t 0:00:00.002163\n",
      "\t 0:00:00.019605\n",
      "\t subcomp 0:00:00.119569\n",
      "stroke\n",
      "\t 0:00:00.093431\n",
      "\t 0:00:00.002463\n",
      "\t 0:00:00.052199\n",
      "\t stroke 0:00:00.148285\n",
      "\t\t 0:00:00.764464\n",
      "0:00:00.889875\n",
      "char\n",
      "\t 0:00:00.104369\n",
      "\t 0:00:00.001461\n",
      "\t 0:00:00.009682\n",
      "\t char 0:00:00.115691\n",
      "basic\n",
      "\t 0:00:00.112040\n",
      "\t 0:00:00.001753\n",
      "\t 0:00:00.010252\n",
      "\t basic 0:00:00.124224\n",
      "medical\n",
      "\t 0:00:00.103922\n",
      "\t 0:00:00.001467\n",
      "\t 0:00:00.009727\n",
      "\t medical 0:00:00.115220\n",
      "radical\n",
      "\t 0:00:00.103217\n",
      "\t 0:00:00.003209\n",
      "\t 0:00:00.012230\n",
      "\t radical 0:00:00.118909\n",
      "subcomp\n",
      "\t 0:00:00.142694\n",
      "\t 0:00:00.003114\n",
      "\t 0:00:00.028293\n",
      "\t subcomp 0:00:00.174515\n",
      "stroke\n",
      "\t 0:00:00.116071\n",
      "\t 0:00:00.001908\n",
      "\t 0:00:00.049637\n",
      "\t stroke 0:00:00.167722\n",
      "\t\t 0:00:00.817291\n",
      "0:00:00.961098\n",
      "char\n",
      "\t 0:00:00.107768\n",
      "\t 0:00:00.002211\n",
      "\t 0:00:00.010829\n",
      "\t char 0:00:00.120926\n",
      "basic\n",
      "\t 0:00:00.127093\n",
      "\t 0:00:00.003156\n",
      "\t 0:00:00.013025\n",
      "\t basic 0:00:00.143887\n",
      "medical\n",
      "\t 0:00:00.122923\n",
      "\t 0:00:00.002866\n",
      "\t 0:00:00.010640\n",
      "\t medical 0:00:00.136563\n",
      "radical\n",
      "\t 0:00:00.112726\n",
      "\t 0:00:00.002419\n",
      "\t 0:00:00.010786\n",
      "\t radical 0:00:00.126056\n",
      "subcomp\n",
      "\t 0:00:00.110817\n",
      "\t 0:00:00.002287\n",
      "\t 0:00:00.021419\n",
      "\t subcomp 0:00:00.134648\n",
      "stroke\n",
      "\t 0:00:00.105307\n",
      "\t 0:00:00.002766\n",
      "\t 0:00:00.058020\n",
      "\t stroke 0:00:00.166270\n",
      "\t\t 0:00:00.829117\n",
      "0:00:00.968328\n",
      "char\n",
      "\t 0:00:00.123753\n",
      "\t 0:00:00.002326\n",
      "\t 0:00:00.010824\n",
      "\t char 0:00:00.137055\n",
      "basic\n",
      "\t 0:00:00.100127\n",
      "\t 0:00:00.002087\n",
      "\t 0:00:00.010415\n",
      "\t basic 0:00:00.112771\n",
      "medical\n",
      "\t 0:00:00.101099\n",
      "\t 0:00:00.002885\n",
      "\t 0:00:00.016885\n",
      "\t medical 0:00:00.121521\n",
      "radical\n",
      "\t 0:00:00.106921\n",
      "\t 0:00:00.001795\n",
      "\t 0:00:00.010526\n",
      "\t radical 0:00:00.119370\n",
      "subcomp\n",
      "\t 0:00:00.098152\n",
      "\t 0:00:00.002477\n",
      "\t 0:00:00.020860\n",
      "\t subcomp 0:00:00.121634\n",
      "stroke\n",
      "\t 0:00:00.098452\n",
      "\t 0:00:00.003137\n",
      "\t 0:00:00.054545\n",
      "\t stroke 0:00:00.156371\n",
      "\t\t 0:00:00.769575\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-19b6b9549e3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0mbatch_right\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mToken\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtk_idx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtk_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch_right\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0mbatch_Right_Channels_Info_Leng\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'token'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgetTokenBatchInfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_right\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'token'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m     \u001b[0mbatch_Right_Channels_Info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch_Right_Channels_Info_Leng\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0mbatch_Right_Channels_Leng\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch_Right_Channels_Info_Leng\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/nlpchannel/nlptext/utils/grain.py\u001b[0m in \u001b[0;36mgetTokenBatchInfo\u001b[0;34m(batch, channel, Max_Ngram, tagScheme, end_grain, TokenNum_Dir)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     Info_Leng = [tk.getGrainTensor(channel, Max_Ngram = Max_Ngram, tagScheme = tagScheme, \n\u001b[0;32m--> 140\u001b[0;31m                                    end_grain = end_grain, TokenNum_Dir= TokenNum_Dir )  for tk in batch]\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/nlpchannel/nlptext/utils/grain.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     Info_Leng = [tk.getGrainTensor(channel, Max_Ngram = Max_Ngram, tagScheme = tagScheme, \n\u001b[0;32m--> 140\u001b[0;31m                                    end_grain = end_grain, TokenNum_Dir= TokenNum_Dir )  for tk in batch]\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/nlpchannel/nlptext/token.py\u001b[0m in \u001b[0;36mgetGrainTensor\u001b[0;34m(self, channel, Max_Ngram, tagScheme, end_grain, TokenNum_Dir, dontUseLookUp)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;31m# print(TokenNum_Dir)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         LGU, DGU = self.getGrainUnique(channel, Max_Ngram, end_grain = end_grain, \n\u001b[0;32m---> 88\u001b[0;31m                                        tagScheme = tagScheme, TokenNum_Dir =TokenNum_Dir)\n\u001b[0m\u001b[1;32m     89\u001b[0m         info = [DGU.get(i, UNK_ID) for i in self.getChannelGrain(channel,Max_Ngram = Max_Ngram, \n\u001b[1;32m     90\u001b[0m                                                                        end_grain = end_grain, tagScheme = tagScheme)]\n",
      "\u001b[0;32m~/Desktop/nlpchannel/nlptext/base.py\u001b[0m in \u001b[0;36mgetGrainUnique\u001b[0;34m(cls, channel, Max_Ngram, end_grain, tagScheme, TokenNum_Dir)\u001b[0m\n\u001b[1;32m    600\u001b[0m             \u001b[0mTokenNum_Dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTokenNum_Dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m             \u001b[0mchannel_name_pickle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTokenNum_Dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'GrainUnique'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannel_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.p'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m             \u001b[0mchannel_name_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTokenNum_Dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannel_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.tsv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mchannel_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGRAIN_UNI\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTokenNum_Dir\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Environments/anaconda3/lib/python3.7/posixpath.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(a, *p)\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0mpath\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m                 \u001b[0mpath\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBytesWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mgenericpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_arg_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'join'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "TVC_left, TVC_right = TVC['left'], TVC['right']\n",
    "from nlptext.utils.channel import getChannelName\n",
    "from datetime import datetime\n",
    "import os\n",
    "UNK_ID = 3\n",
    "\n",
    "\n",
    "self = BasicObject\n",
    "# time_per_100_batch = datetime.now()\n",
    "for step in range(1, 10000+1):\n",
    "    batch_time_start = datetime.now()#################################################\n",
    "    \n",
    "    load_batch_time_start = batch_time_start\n",
    "\n",
    "    # Step1: generate batch data\n",
    "    batch_left, batch_right, data_index = generate_batch(tokenList, data_index,  **BATCH)\n",
    "    # batch_left = [Token(tk_idx) for tk_idx in batch_left]\n",
    "    \n",
    "    s_t = datetime.now()\n",
    "#     batch_Left_Channels_Info_Leng = {ch: getTokenBatchInfo(batch_left, ch, **cs) for ch, cs in CH.items()}\n",
    "\n",
    "    for ch, cs in CH.items():\n",
    "        print(ch)\n",
    "        s_ch = datetime.now()\n",
    "        s = s_ch\n",
    "        \n",
    "        Info_Leng = []\n",
    "        for index in batch_left:\n",
    "            channel_name = getChannelName(ch, **cs)\n",
    "            TokenNum_Dir = cs.get('TokenNum_Dir')\n",
    "            Max_Ngram =  cs.get('Max_Ngram')\n",
    "            end_grain=  cs.get('end_grain')\n",
    "            tagScheme =  cs.get('tagScheme', 'BIO')\n",
    "            tmp_TokenNum_Dir = TokenNum_Dir if TokenNum_Dir else self.TokenNum_Dir\n",
    "            lookup_channel_name_path = os.path.join(tmp_TokenNum_Dir, 'LookUp', channel_name + '.p')\n",
    "            if os.path.isfile(lookup_channel_name_path):\n",
    "                ### case 1: deal with the case: CTX_IND channel and this channel has LOOKUP.p\n",
    "                LOOKUP, TokenUnqiue = self.getLookUp(ch, Max_Ngram, end_grain = end_grain, \n",
    "                                                     tagScheme = tagScheme, TokenNum_Dir = TokenNum_Dir)\n",
    "\n",
    "                LTU, DTU = TokenUnqiue\n",
    "                # index = 9\n",
    "\n",
    "                if index != UNK_ID:\n",
    "                    # print('\\tUse LookUp from:'+lookup_channel_name_path)\n",
    "                    info = LOOKUP[index] # TODO, to do what?\n",
    "                    # info = np.array(info)\n",
    "                    leng = np.array(len(info), dtype='float32')\n",
    "                    # leng = len(info)\n",
    "            Info_Leng.append((info, leng))\n",
    "        e = datetime.now()\n",
    "        print('\\t', e - s)\n",
    "        \n",
    "        s = datetime.now()\n",
    "        # channelLeng = [info_leng[1] for info_leng in Info_Leng] # little\n",
    "        # channelLeng = np.array(channelLeng)\n",
    "        channelLeng = np.array([info_leng[1] for info_leng in Info_Leng], dtype='float32')\n",
    "        \n",
    "        maxGrainLeng = int(np.max(channelLeng))\n",
    "        channelInfo = [info_leng[0] for info_leng in Info_Leng]\n",
    "        e = datetime.now()\n",
    "        print('\\t', e - s)\n",
    "        \n",
    "        s = datetime.now()\n",
    "#         channelInfo = np.array([np.pad(info,[0,maxGrainLeng - len(info)], 'constant') for info in channelInfo])\n",
    "        channelInfo_Final =np.zeros([len(channelInfo), maxGrainLeng], dtype=int)\n",
    "        for idx, info in enumerate(channelInfo):\n",
    "            channelInfo_Final[idx, :len(info)] = channelInfo[idx]\n",
    "        e = datetime.now()\n",
    "        print('\\t', e - s)\n",
    "        \n",
    "        e_ch = e\n",
    "        print('\\t', ch, e_ch - s_ch)\n",
    "    \n",
    "    \n",
    "    e_t = datetime.now()\n",
    "    print('\\t\\t', e_t - s_t)\n",
    "    \n",
    "    # batch_Left_Channels_Info = {ch:v[0] for ch, v in batch_Left_Channels_Info_Leng.items()}\n",
    "    # batch_Left_Channels_Leng = {ch:v[1] for ch, v in batch_Left_Channels_Info_Leng.items()}\\\n",
    "    \n",
    "    \n",
    "    batch_right = [Token(tk_idx) for tk_idx in batch_right]\n",
    "    \n",
    "    batch_Right_Channels_Info_Leng = {'token': getTokenBatchInfo(batch_right, 'token')}\n",
    "    batch_Right_Channels_Info = {ch:v[0] for ch, v in batch_Right_Channels_Info_Leng.items()}\n",
    "    batch_Right_Channels_Leng = {ch:v[1] for ch, v in batch_Right_Channels_Info_Leng.items()}\n",
    "    \n",
    "    load_batch_time_end = datetime.now()\n",
    "    print(load_batch_time_end - load_batch_time_start)#################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from datetime import datetime\n",
    "# TVC_left, TVC_right = TVC['left'], TVC['right']\n",
    "# from nlptext.utils.channel import getChannelName\n",
    "# from datetime import datetime\n",
    "# import os\n",
    "# UNK_ID = 3\n",
    "\n",
    "\n",
    "# self = BasicObject\n",
    "# # time_per_100_batch = datetime.now()\n",
    "# for step in range(1, 10000+1):\n",
    "#     batch_time_start = datetime.now()#################################################\n",
    "    \n",
    "#     load_batch_time_start = batch_time_start\n",
    "\n",
    "#     # Step1: generate batch data\n",
    "#     batch_left, batch_right, data_index = generate_batch(tokenList, data_index,  **BATCH)\n",
    "#     # batch_left = [Token(tk_idx) for tk_idx in batch_left]\n",
    "    \n",
    "#     s_t = datetime.now()\n",
    "# #     batch_Left_Channels_Info_Leng = {ch: getTokenBatchInfo(batch_left, ch, **cs) for ch, cs in CH.items()}\n",
    "\n",
    "#     for ch, cs in CH.items():\n",
    "#         print(ch)\n",
    "#         s_ch = datetime.now()\n",
    "#         s = s_ch\n",
    "        \n",
    "#         Info_Leng = []\n",
    "#         for index in batch_left:\n",
    "#             channel_name = getChannelName(ch, **cs)\n",
    "#             TokenNum_Dir = cs.get('TokenNum_Dir')\n",
    "#             Max_Ngram =  cs.get('Max_Ngram')\n",
    "#             end_grain=  cs.get('end_grain')\n",
    "#             tagScheme =  cs.get('tagScheme', 'BIO')\n",
    "#             tmp_TokenNum_Dir = TokenNum_Dir if TokenNum_Dir else self.TokenNum_Dir\n",
    "#             lookup_channel_name_path = os.path.join(tmp_TokenNum_Dir, 'LookUp', channel_name + '.p')\n",
    "#             if os.path.isfile(lookup_channel_name_path):\n",
    "#                 ### case 1: deal with the case: CTX_IND channel and this channel has LOOKUP.p\n",
    "#                 LOOKUP, TokenUnqiue = self.getLookUp(ch, Max_Ngram, end_grain = end_grain, \n",
    "#                                                      tagScheme = tagScheme, TokenNum_Dir = TokenNum_Dir)\n",
    "\n",
    "#                 LTU, DTU = TokenUnqiue\n",
    "#                 # index = 9\n",
    "\n",
    "#                 if index != UNK_ID:\n",
    "#                     # print('\\tUse LookUp from:'+lookup_channel_name_path)\n",
    "#                     info = LOOKUP[index] # TODO, to do what?\n",
    "#                     # info = np.array(info)\n",
    "#                     # leng = np.array(len(info), dtype='float32')\n",
    "#                     leng = len(info)\n",
    "#             Info_Leng.append((info, leng))\n",
    "#         e = datetime.now()\n",
    "#         print('\\t', e - s)\n",
    "        \n",
    "#         s = datetime.now()\n",
    "#         # channelLeng = [info_leng[1] for info_leng in Info_Leng] # little\n",
    "#         # channelLeng = np.array(channelLeng)\n",
    "#         channelLeng = np.array([info_leng[1] for info_leng in Info_Leng], dtype='float32')\n",
    "        \n",
    "#         maxGrainLeng = int(np.max(channelLeng))\n",
    "#         channelInfo = [info_leng[0] for info_leng in Info_Leng]\n",
    "#         e = datetime.now()\n",
    "#         print('\\t', e - s)\n",
    "        \n",
    "#         s = datetime.now()\n",
    "# #         channelInfo = np.array([np.pad(info,[0,maxGrainLeng - len(info)], 'constant') for info in channelInfo])\n",
    "#         channelInfo_Final =np.zeros([len(channelInfo), maxGrainLeng], dtype=int)\n",
    "#         for idx, info in enumerate(channelInfo):\n",
    "#             channelInfo_Final[idx, :len(info)] = channelInfo[idx]\n",
    "#         e = datetime.now()\n",
    "#         print('\\t', e - s)\n",
    "        \n",
    "#         e_ch = e\n",
    "#         print('\\t', ch, e_ch - s_ch)\n",
    "    \n",
    "    \n",
    "#     e_t = datetime.now()\n",
    "#     print('\\t\\t', e_t - s_t)\n",
    "    \n",
    "#     # batch_Left_Channels_Info = {ch:v[0] for ch, v in batch_Left_Channels_Info_Leng.items()}\n",
    "#     # batch_Left_Channels_Leng = {ch:v[1] for ch, v in batch_Left_Channels_Info_Leng.items()}\\\n",
    "    \n",
    "    \n",
    "#     s_t = datetime.now()\n",
    "    \n",
    "#     batch_right = [Token(tk_idx) for tk_idx in batch_right]\n",
    "    \n",
    "#     batch_Right_Channels_Info_Leng = {'token': getTokenBatchInfo(batch_right, 'token')}\n",
    "#     batch_Right_Channels_Info = {ch:v[0] for ch, v in batch_Right_Channels_Info_Leng.items()}\n",
    "#     batch_Right_Channels_Leng = {ch:v[1] for ch, v in batch_Right_Channels_Info_Leng.items()}\n",
    "#     e_t = datetime.now()\n",
    "#     print('\\t\\t', e_t - s_t)\n",
    "    \n",
    "    \n",
    "#     load_batch_time_end = datetime.now()\n",
    "#     print(load_batch_time_end - load_batch_time_start)#################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORPUS\tread from pickle file : channel/WikiTotal/word/Token447170/Pyramid/CORPUS.p\n",
      "CORPUS\tthe length of it is   : 1\n",
      "FOLDER\tread from pickle file : channel/WikiTotal/word/Token447170/Pyramid/FOLDER.p\n",
      "FOLDER\tthe length of it is   : 1\n",
      "TEXT\tread from pickle file : channel/WikiTotal/word/Token447170/Pyramid/TEXT.p\n",
      "TEXT\tthe length of it is   : 4717592\n",
      "SENT\tread from pickle file : channel/WikiTotal/word/Token447170/Pyramid/SENT.p\n",
      "SENT\tthe length of it is   : 11199643\n",
      "TOKEN\tread from pickle file : channel/WikiTotal/word/Token447170/Pyramid/TOKEN.p\n",
      "TOKEN\tthe length of it is   : 257789077\n",
      "**************************************** \n",
      "\n",
      "token\tread from pickle file : channel/WikiTotal/word/Token447170/GrainUnique/token.p\n",
      "token\tthe length of it is   : 447170\n",
      "**************************************** \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nlptext.token import Token\n",
    "from nlptext.utils.grain import generate_batch, getTokenBatchInfo\n",
    "\n",
    "from config_embed import CHANNEL_SETTINGS_TEMPLATE, TK_VEC_CHANNEL_SETTINGS_TEMPLATE\n",
    "from config_embed import MERGING_SETTINGS_TEMPLATE, BATCH_SETTINGS_TEMPLATE\n",
    "from config_embed import EMBED_TRAINING_SETTINGS_TEMPLATE\n",
    "\n",
    "from nlptext.base import BasicObject\n",
    "\n",
    "from nlpembed.config_factory import setting_factory\n",
    "#from nlpembed.train import Train_Embedding\n",
    "from nlptext.utils.channel import getChannelName\n",
    "from datetime import datetime\n",
    "\n",
    "BOB = 'channel/WikiTotal/word/Token447170/Pyramid'\n",
    "LGU = 'channel/WikiTotal/word/Token447170/GrainUnique'\n",
    "BasicObject.INIT_FROM_PICKLE(BOB, LGU)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# 10000\n",
    "char\n",
    "0:00:00.095421\n",
    "basic\n",
    "0:00:00.095452\n",
    "medical\n",
    "0:00:00.088307\n",
    "radical\n",
    "0:00:00.085013\n",
    "subcomp\n",
    "0:00:00.088327\n",
    "stroke\n",
    "0:00:00.084229\n",
    "token\n",
    "0:00:00.122542\n",
    "Total time: 0:00:00.660324\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# 5000\n",
    "char\n",
    "0:00:00.061882\n",
    "basic\n",
    "0:00:00.043449\n",
    "medical\n",
    "0:00:00.042075\n",
    "radical\n",
    "0:00:00.041467\n",
    "subcomp\n",
    "0:00:00.045256\n",
    "stroke\n",
    "0:00:00.041615\n",
    "token\n",
    "0:00:00.062675\n",
    "Total time: 0:00:00.339320\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PAD   = '</pad>'\n",
    "START = '</start>'\n",
    "END   = '</end>'\n",
    "UNK   = '</unk>'\n",
    "specialTokens     = [ PAD, START, END, UNK]\n",
    "\n",
    "\n",
    "def trans_bioesTag(channel, bioesTag, tagScheme):\n",
    "\n",
    "    if bioesTag in specialTokens:\n",
    "        return bioesTag\n",
    "        \n",
    "    if 'S' not in tagScheme and 'E' not in tagScheme:\n",
    "        i = bioesTag.replace('-S', '-B').replace('-E', '-I')\n",
    "    elif 'S' not in tagScheme:\n",
    "        i = bioesTag.replace('-S', '-B')\n",
    "    elif 'E' not in tagScheme:\n",
    "        i = bioesTag.replace('-E', '-I')\n",
    "    else:\n",
    "        i = bioesTag\n",
    "\n",
    "    if channel == 'annoR':\n",
    "        return i.split('-')[-1] \n",
    "    else:\n",
    "        return i\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def readFile2GrainList(channel_name_path):\n",
    "    ListGrainUnique = []\n",
    "    with open(channel_name_path, 'r', encoding = 'utf-8') as f:\n",
    "        for gr in f.readlines():\n",
    "            gr = '\\n' if  '\\\\n' in gr[:-1] else gr[:-1]\n",
    "            ListGrainUnique.append(gr)\n",
    "    return ListGrainUnique\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "bioesLGU = readFile2GrainList(channel_name_path='channel/LuohuNER/char/Token1601/annoE-bioes.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['</pad>',\n",
       " '</start>',\n",
       " '</end>',\n",
       " 'O',\n",
       " '主体-B',\n",
       " '主体-E',\n",
       " '主体-I',\n",
       " '主体-S',\n",
       " '异常-B',\n",
       " '异常-E',\n",
       " '异常-I',\n",
       " '异常-S',\n",
       " '异常分类-B',\n",
       " '异常分类-E',\n",
       " '异常分类-I',\n",
       " '异常分类-S',\n",
       " '检查-B',\n",
       " '检查-E',\n",
       " '检查-I',\n",
       " '检查-S',\n",
       " '治疗-B',\n",
       " '治疗-E',\n",
       " '治疗-I',\n",
       " '治疗-S']"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bioesLGU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['</pad>', '</start>', '</end>', 'B', 'E', 'I', 'O', 'S']"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channel = 'annoR'\n",
    "tagScheme = 'BIOES'\n",
    "\n",
    "new_LGU = [trans_bioesTag(channel, i, tagScheme) for i in bioesLGU]\n",
    "\n",
    "b = list(set(new_LGU[3:]))\n",
    "b.sort()\n",
    "new_LGU = new_LGU[:3] + b\n",
    "new_LGU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'</pad>': 0,\n",
       " '</start>': 1,\n",
       " '</end>': 2,\n",
       " 'B': 3,\n",
       " 'E': 4,\n",
       " 'I': 5,\n",
       " 'O': 6,\n",
       " 'S': 7}"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "new_DGU = dict(zip(new_LGU, range(len(new_LGU))))\n",
    "new_DGU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0,\n",
       " 1: 1,\n",
       " 2: 2,\n",
       " 3: 6,\n",
       " 4: 3,\n",
       " 5: 4,\n",
       " 6: 5,\n",
       " 7: 7,\n",
       " 8: 3,\n",
       " 9: 4,\n",
       " 10: 5,\n",
       " 11: 7,\n",
       " 12: 3,\n",
       " 13: 4,\n",
       " 14: 5,\n",
       " 15: 7,\n",
       " 16: 3,\n",
       " 17: 4,\n",
       " 18: 5,\n",
       " 19: 7,\n",
       " 20: 3,\n",
       " 21: 4,\n",
       " 22: 5,\n",
       " 23: 7}"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " {idx: new_DGU[trans_bioesTag(channel, bioesTag, tagScheme )] \n",
    "                                                   for idx, bioesTag in enumerate(bioesLGU)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'</pad>': '</pad>',\n",
       " '</start>': '</start>',\n",
       " '</end>': '</end>',\n",
       " 'O': 'O',\n",
       " '主体-B': 'B',\n",
       " '主体-E': 'E',\n",
       " '主体-I': 'I',\n",
       " '主体-S': 'S',\n",
       " '异常-B': 'B',\n",
       " '异常-E': 'E',\n",
       " '异常-I': 'I',\n",
       " '异常-S': 'S',\n",
       " '异常分类-B': 'B',\n",
       " '异常分类-E': 'E',\n",
       " '异常分类-I': 'I',\n",
       " '异常分类-S': 'S',\n",
       " '检查-B': 'B',\n",
       " '检查-E': 'E',\n",
       " '检查-I': 'I',\n",
       " '检查-S': 'S',\n",
       " '治疗-B': 'B',\n",
       " '治疗-E': 'E',\n",
       " '治疗-I': 'I',\n",
       " '治疗-S': 'S'}"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " {bioesTag: trans_bioesTag(channel, bioesTag, tagScheme )\n",
    "                                                   for idx, bioesTag in enumerate(bioesLGU)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Batch Load Speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORPUS\tread from pickle file : data/LuohuCorpus/char/Token3546/Pyramid/CORPUS.p\n",
      "CORPUS\tthe length of it is   : 1\n",
      "FOLDER\tread from pickle file : data/LuohuCorpus/char/Token3546/Pyramid/FOLDER.p\n",
      "FOLDER\tthe length of it is   : 44\n",
      "TEXT\tread from pickle file : data/LuohuCorpus/char/Token3546/Pyramid/TEXT.p\n",
      "TEXT\tthe length of it is   : 227876\n",
      "SENT\tread from pickle file : data/LuohuCorpus/char/Token3546/Pyramid/SENT.p\n",
      "SENT\tthe length of it is   : 1213151\n",
      "TOKEN\tread from pickle file : data/LuohuCorpus/char/Token3546/Pyramid/TOKEN.p\n",
      "TOKEN\tthe length of it is   : 36760202\n",
      "**************************************** \n",
      "\n",
      "token\tread from pickle file : data/LuohuCorpus/char/Token3546/GrainUnique/token.p\n",
      "token\tthe length of it is   : 3546\n",
      "**************************************** \n",
      "\n",
      "Deal with the Channel: token\n",
      "Current Channel is        \t token\n",
      "Current Channel Max_Ngram \t 1\n",
      "Deal with the Channel: char\n",
      "Current Channel is        \t char\n",
      "Current Channel Max_Ngram \t 1\n",
      "Deal with the Channel: basic\n",
      "Current Channel is        \t basic\n",
      "Current Channel Max_Ngram \t 1\n",
      "Deal with the Channel: medical\n",
      "Current Channel is        \t medical\n",
      "Current Channel Max_Ngram \t 1\n",
      "Deal with the Channel: radical\n",
      "Current Channel is        \t radical\n",
      "Current Channel Max_Ngram \t 1\n",
      "Deal with the Channel: subcomp\n",
      "Current Channel is        \t subcomp\n",
      "Current Channel Max_Ngram \t 3\n",
      "Deal with the Channel: stroke\n",
      "Current Channel is        \t stroke\n",
      "Current Channel Max_Ngram \t 5\n",
      "Deal with the Channel: pos\n",
      "Current Channel is        \t pos\n",
      "Current Channel Max_Ngram \t 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pprint import pprint\n",
    "from nlptext.base import BasicObject\n",
    "\n",
    "CHANNEL_SETTINGS_TEMPLATE = {\n",
    "    # CTX_IND\n",
    "    'token':   {'use': True, 'Max_Ngram': 1,},\n",
    "    'char':    {'use': True,'Max_Ngram': 1, 'end_grain': False},\n",
    "    'basic':   {'use': True,'Max_Ngram': 1, 'end_grain': False},\n",
    "    'medical': {'use': True,'Max_Ngram': 1, 'end_grain': False},\n",
    "    'radical': {'use': True,'Max_Ngram': 1, 'end_grain': False},\n",
    "    'subcomp': {'use': True,'Max_Ngram': 3, 'end_grain': True},\n",
    "    'stroke':  {'use': True,'Max_Ngram': 5, 'end_grain': True},\n",
    "    # CTX_DEP\n",
    "    'pos':     {'use': True,'Max_Ngram': 1, 'end_grain': False, 'tagScheme':   'BIO',},\n",
    "    # ANNO\n",
    "    'annoR':   {'use': False,'Max_Ngram': 1, 'end_grain': False, 'tagScheme':   'BIO',},\n",
    "    'annoE':   {'use': False,'Max_Ngram': 1, 'end_grain': False, 'tagScheme':   'BIO',},\n",
    "}\n",
    "\n",
    "# Path2Pyramid = 'data/boson/char/Token3870/Pyramid/'\n",
    "# Path2LGUnique = 'data/boson/char/Token3870/GrainUnique/'\n",
    "\n",
    "\n",
    "\n",
    "Path2Pyramid  = 'data/LuohuCorpus/char/Token3546/Pyramid/'\n",
    "Path2LGUnique = 'data/LuohuCorpus/char/Token3546/GrainUnique/'\n",
    "\n",
    "\n",
    "\n",
    "BasicObject.INIT_FROM_PICKLE(Path2Pyramid, Path2LGUnique)\n",
    "\n",
    "BasicObject.BUILD_GRAIN_UNI_AND_LOOKUP(CHANNEL_SETTINGS_TEMPLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'skip_window': 5, 'batch_token_num': 1000, 'maxlen': 36760202, 'left2right': 'tgt-ctx', 'size2size': '1-1', 'tgtInctx': False, 'batch_size': 10000}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(5, 0),\n",
       " (5, 1),\n",
       " (5, 2),\n",
       " (5, 3),\n",
       " (5, 4),\n",
       " (5, 6),\n",
       " (5, 7),\n",
       " (5, 8),\n",
       " (5, 9),\n",
       " (5, 10),\n",
       " (6, 1),\n",
       " (6, 2),\n",
       " (6, 3),\n",
       " (6, 4),\n",
       " (6, 5),\n",
       " (6, 7),\n",
       " (6, 8),\n",
       " (6, 9),\n",
       " (6, 10),\n",
       " (6, 11),\n",
       " (7, 2),\n",
       " (7, 3),\n",
       " (7, 4),\n",
       " (7, 5),\n",
       " (7, 6),\n",
       " (7, 8),\n",
       " (7, 9),\n",
       " (7, 10),\n",
       " (7, 11),\n",
       " (7, 12),\n",
       " (8, 3),\n",
       " (8, 4),\n",
       " (8, 5),\n",
       " (8, 6),\n",
       " (8, 7),\n",
       " (8, 9),\n",
       " (8, 10),\n",
       " (8, 11),\n",
       " (8, 12),\n",
       " (8, 13),\n",
       " (9, 4),\n",
       " (9, 5),\n",
       " (9, 6),\n",
       " (9, 7),\n",
       " (9, 8),\n",
       " (9, 10),\n",
       " (9, 11),\n",
       " (9, 12),\n",
       " (9, 13),\n",
       " (9, 14),\n",
       " (10, 5),\n",
       " (10, 6),\n",
       " (10, 7),\n",
       " (10, 8),\n",
       " (10, 9),\n",
       " (10, 11),\n",
       " (10, 12),\n",
       " (10, 13),\n",
       " (10, 14),\n",
       " (10, 15),\n",
       " (11, 6),\n",
       " (11, 7),\n",
       " (11, 8),\n",
       " (11, 9),\n",
       " (11, 10),\n",
       " (11, 12),\n",
       " (11, 13),\n",
       " (11, 14),\n",
       " (11, 15),\n",
       " (11, 16),\n",
       " (12, 7),\n",
       " (12, 8),\n",
       " (12, 9),\n",
       " (12, 10),\n",
       " (12, 11),\n",
       " (12, 13),\n",
       " (12, 14),\n",
       " (12, 15),\n",
       " (12, 16),\n",
       " (12, 17),\n",
       " (13, 8),\n",
       " (13, 9),\n",
       " (13, 10),\n",
       " (13, 11),\n",
       " (13, 12),\n",
       " (13, 14),\n",
       " (13, 15),\n",
       " (13, 16),\n",
       " (13, 17),\n",
       " (13, 18),\n",
       " (14, 9),\n",
       " (14, 10),\n",
       " (14, 11),\n",
       " (14, 12),\n",
       " (14, 13),\n",
       " (14, 15),\n",
       " (14, 16),\n",
       " (14, 17),\n",
       " (14, 18),\n",
       " (14, 19),\n",
       " (15, 10),\n",
       " (15, 11),\n",
       " (15, 12),\n",
       " (15, 13),\n",
       " (15, 14),\n",
       " (15, 16),\n",
       " (15, 17),\n",
       " (15, 18),\n",
       " (15, 19),\n",
       " (15, 20),\n",
       " (16, 11),\n",
       " (16, 12),\n",
       " (16, 13),\n",
       " (16, 14),\n",
       " (16, 15),\n",
       " (16, 17),\n",
       " (16, 18),\n",
       " (16, 19),\n",
       " (16, 20),\n",
       " (16, 21),\n",
       " (17, 12),\n",
       " (17, 13),\n",
       " (17, 14),\n",
       " (17, 15),\n",
       " (17, 16),\n",
       " (17, 18),\n",
       " (17, 19),\n",
       " (17, 20),\n",
       " (17, 21),\n",
       " (17, 22),\n",
       " (18, 13),\n",
       " (18, 14),\n",
       " (18, 15),\n",
       " (18, 16),\n",
       " (18, 17),\n",
       " (18, 19),\n",
       " (18, 20),\n",
       " (18, 21),\n",
       " (18, 22),\n",
       " (18, 23),\n",
       " (19, 14),\n",
       " (19, 15),\n",
       " (19, 16),\n",
       " (19, 17),\n",
       " (19, 18),\n",
       " (19, 20),\n",
       " (19, 21),\n",
       " (19, 22),\n",
       " (19, 23),\n",
       " (19, 24),\n",
       " (20, 15),\n",
       " (20, 16),\n",
       " (20, 17),\n",
       " (20, 18),\n",
       " (20, 19),\n",
       " (20, 21),\n",
       " (20, 22),\n",
       " (20, 23),\n",
       " (20, 24),\n",
       " (20, 25),\n",
       " (21, 16),\n",
       " (21, 17),\n",
       " (21, 18),\n",
       " (21, 19),\n",
       " (21, 20),\n",
       " (21, 22),\n",
       " (21, 23),\n",
       " (21, 24),\n",
       " (21, 25),\n",
       " (21, 26),\n",
       " (22, 17),\n",
       " (22, 18),\n",
       " (22, 19),\n",
       " (22, 20),\n",
       " (22, 21),\n",
       " (22, 23),\n",
       " (22, 24),\n",
       " (22, 25),\n",
       " (22, 26),\n",
       " (22, 27),\n",
       " (23, 18),\n",
       " (23, 19),\n",
       " (23, 20),\n",
       " (23, 21),\n",
       " (23, 22),\n",
       " (23, 24),\n",
       " (23, 25),\n",
       " (23, 26),\n",
       " (23, 27),\n",
       " (23, 28),\n",
       " (24, 19),\n",
       " (24, 20),\n",
       " (24, 21),\n",
       " (24, 22),\n",
       " (24, 23),\n",
       " (24, 25),\n",
       " (24, 26),\n",
       " (24, 27),\n",
       " (24, 28),\n",
       " (24, 29),\n",
       " (25, 20),\n",
       " (25, 21),\n",
       " (25, 22),\n",
       " (25, 23),\n",
       " (25, 24),\n",
       " (25, 26),\n",
       " (25, 27),\n",
       " (25, 28),\n",
       " (25, 29),\n",
       " (25, 30),\n",
       " (26, 21),\n",
       " (26, 22),\n",
       " (26, 23),\n",
       " (26, 24),\n",
       " (26, 25),\n",
       " (26, 27),\n",
       " (26, 28),\n",
       " (26, 29),\n",
       " (26, 30),\n",
       " (26, 31),\n",
       " (27, 22),\n",
       " (27, 23),\n",
       " (27, 24),\n",
       " (27, 25),\n",
       " (27, 26),\n",
       " (27, 28),\n",
       " (27, 29),\n",
       " (27, 30),\n",
       " (27, 31),\n",
       " (27, 32),\n",
       " (28, 23),\n",
       " (28, 24),\n",
       " (28, 25),\n",
       " (28, 26),\n",
       " (28, 27),\n",
       " (28, 29),\n",
       " (28, 30),\n",
       " (28, 31),\n",
       " (28, 32),\n",
       " (28, 33),\n",
       " (29, 24),\n",
       " (29, 25),\n",
       " (29, 26),\n",
       " (29, 27),\n",
       " (29, 28),\n",
       " (29, 30),\n",
       " (29, 31),\n",
       " (29, 32),\n",
       " (29, 33),\n",
       " (29, 34),\n",
       " (30, 25),\n",
       " (30, 26),\n",
       " (30, 27),\n",
       " (30, 28),\n",
       " (30, 29),\n",
       " (30, 31),\n",
       " (30, 32),\n",
       " (30, 33),\n",
       " (30, 34),\n",
       " (30, 35),\n",
       " (31, 26),\n",
       " (31, 27),\n",
       " (31, 28),\n",
       " (31, 29),\n",
       " (31, 30),\n",
       " (31, 32),\n",
       " (31, 33),\n",
       " (31, 34),\n",
       " (31, 35),\n",
       " (31, 36),\n",
       " (32, 27),\n",
       " (32, 28),\n",
       " (32, 29),\n",
       " (32, 30),\n",
       " (32, 31),\n",
       " (32, 33),\n",
       " (32, 34),\n",
       " (32, 35),\n",
       " (32, 36),\n",
       " (32, 37),\n",
       " (33, 28),\n",
       " (33, 29),\n",
       " (33, 30),\n",
       " (33, 31),\n",
       " (33, 32),\n",
       " (33, 34),\n",
       " (33, 35),\n",
       " (33, 36),\n",
       " (33, 37),\n",
       " (33, 38),\n",
       " (34, 29),\n",
       " (34, 30),\n",
       " (34, 31),\n",
       " (34, 32),\n",
       " (34, 33),\n",
       " (34, 35),\n",
       " (34, 36),\n",
       " (34, 37),\n",
       " (34, 38),\n",
       " (34, 39),\n",
       " (35, 30),\n",
       " (35, 31),\n",
       " (35, 32),\n",
       " (35, 33),\n",
       " (35, 34),\n",
       " (35, 36),\n",
       " (35, 37),\n",
       " (35, 38),\n",
       " (35, 39),\n",
       " (35, 40),\n",
       " (36, 31),\n",
       " (36, 32),\n",
       " (36, 33),\n",
       " (36, 34),\n",
       " (36, 35),\n",
       " (36, 37),\n",
       " (36, 38),\n",
       " (36, 39),\n",
       " (36, 40),\n",
       " (36, 41),\n",
       " (37, 32),\n",
       " (37, 33),\n",
       " (37, 34),\n",
       " (37, 35),\n",
       " (37, 36),\n",
       " (37, 38),\n",
       " (37, 39),\n",
       " (37, 40),\n",
       " (37, 41),\n",
       " (37, 42),\n",
       " (38, 33),\n",
       " (38, 34),\n",
       " (38, 35),\n",
       " (38, 36),\n",
       " (38, 37),\n",
       " (38, 39),\n",
       " (38, 40),\n",
       " (38, 41),\n",
       " (38, 42),\n",
       " (38, 43),\n",
       " (39, 34),\n",
       " (39, 35),\n",
       " (39, 36),\n",
       " (39, 37),\n",
       " (39, 38),\n",
       " (39, 40),\n",
       " (39, 41),\n",
       " (39, 42),\n",
       " (39, 43),\n",
       " (39, 44),\n",
       " (40, 35),\n",
       " (40, 36),\n",
       " (40, 37),\n",
       " (40, 38),\n",
       " (40, 39),\n",
       " (40, 41),\n",
       " (40, 42),\n",
       " (40, 43),\n",
       " (40, 44),\n",
       " (40, 45),\n",
       " (41, 36),\n",
       " (41, 37),\n",
       " (41, 38),\n",
       " (41, 39),\n",
       " (41, 40),\n",
       " (41, 42),\n",
       " (41, 43),\n",
       " (41, 44),\n",
       " (41, 45),\n",
       " (41, 46),\n",
       " (42, 37),\n",
       " (42, 38),\n",
       " (42, 39),\n",
       " (42, 40),\n",
       " (42, 41),\n",
       " (42, 43),\n",
       " (42, 44),\n",
       " (42, 45),\n",
       " (42, 46),\n",
       " (42, 47),\n",
       " (43, 38),\n",
       " (43, 39),\n",
       " (43, 40),\n",
       " (43, 41),\n",
       " (43, 42),\n",
       " (43, 44),\n",
       " (43, 45),\n",
       " (43, 46),\n",
       " (43, 47),\n",
       " (43, 48),\n",
       " (44, 39),\n",
       " (44, 40),\n",
       " (44, 41),\n",
       " (44, 42),\n",
       " (44, 43),\n",
       " (44, 45),\n",
       " (44, 46),\n",
       " (44, 47),\n",
       " (44, 48),\n",
       " (44, 49),\n",
       " (45, 40),\n",
       " (45, 41),\n",
       " (45, 42),\n",
       " (45, 43),\n",
       " (45, 44),\n",
       " (45, 46),\n",
       " (45, 47),\n",
       " (45, 48),\n",
       " (45, 49),\n",
       " (45, 50),\n",
       " (46, 41),\n",
       " (46, 42),\n",
       " (46, 43),\n",
       " (46, 44),\n",
       " (46, 45),\n",
       " (46, 47),\n",
       " (46, 48),\n",
       " (46, 49),\n",
       " (46, 50),\n",
       " (46, 51),\n",
       " (47, 42),\n",
       " (47, 43),\n",
       " (47, 44),\n",
       " (47, 45),\n",
       " (47, 46),\n",
       " (47, 48),\n",
       " (47, 49),\n",
       " (47, 50),\n",
       " (47, 51),\n",
       " (47, 52),\n",
       " (48, 43),\n",
       " (48, 44),\n",
       " (48, 45),\n",
       " (48, 46),\n",
       " (48, 47),\n",
       " (48, 49),\n",
       " (48, 50),\n",
       " (48, 51),\n",
       " (48, 52),\n",
       " (48, 53),\n",
       " (49, 44),\n",
       " (49, 45),\n",
       " (49, 46),\n",
       " (49, 47),\n",
       " (49, 48),\n",
       " (49, 50),\n",
       " (49, 51),\n",
       " (49, 52),\n",
       " (49, 53),\n",
       " (49, 54),\n",
       " (50, 45),\n",
       " (50, 46),\n",
       " (50, 47),\n",
       " (50, 48),\n",
       " (50, 49),\n",
       " (50, 51),\n",
       " (50, 52),\n",
       " (50, 53),\n",
       " (50, 54),\n",
       " (50, 55),\n",
       " (51, 46),\n",
       " (51, 47),\n",
       " (51, 48),\n",
       " (51, 49),\n",
       " (51, 50),\n",
       " (51, 52),\n",
       " (51, 53),\n",
       " (51, 54),\n",
       " (51, 55),\n",
       " (51, 56),\n",
       " (52, 47),\n",
       " (52, 48),\n",
       " (52, 49),\n",
       " (52, 50),\n",
       " (52, 51),\n",
       " (52, 53),\n",
       " (52, 54),\n",
       " (52, 55),\n",
       " (52, 56),\n",
       " (52, 57),\n",
       " (53, 48),\n",
       " (53, 49),\n",
       " (53, 50),\n",
       " (53, 51),\n",
       " (53, 52),\n",
       " (53, 54),\n",
       " (53, 55),\n",
       " (53, 56),\n",
       " (53, 57),\n",
       " (53, 58),\n",
       " (54, 49),\n",
       " (54, 50),\n",
       " (54, 51),\n",
       " (54, 52),\n",
       " (54, 53),\n",
       " (54, 55),\n",
       " (54, 56),\n",
       " (54, 57),\n",
       " (54, 58),\n",
       " (54, 59),\n",
       " (55, 50),\n",
       " (55, 51),\n",
       " (55, 52),\n",
       " (55, 53),\n",
       " (55, 54),\n",
       " (55, 56),\n",
       " (55, 57),\n",
       " (55, 58),\n",
       " (55, 59),\n",
       " (55, 60),\n",
       " (56, 51),\n",
       " (56, 52),\n",
       " (56, 53),\n",
       " (56, 54),\n",
       " (56, 55),\n",
       " (56, 57),\n",
       " (56, 58),\n",
       " (56, 59),\n",
       " (56, 60),\n",
       " (56, 61),\n",
       " (57, 52),\n",
       " (57, 53),\n",
       " (57, 54),\n",
       " (57, 55),\n",
       " (57, 56),\n",
       " (57, 58),\n",
       " (57, 59),\n",
       " (57, 60),\n",
       " (57, 61),\n",
       " (57, 62),\n",
       " (58, 53),\n",
       " (58, 54),\n",
       " (58, 55),\n",
       " (58, 56),\n",
       " (58, 57),\n",
       " (58, 59),\n",
       " (58, 60),\n",
       " (58, 61),\n",
       " (58, 62),\n",
       " (58, 63),\n",
       " (59, 54),\n",
       " (59, 55),\n",
       " (59, 56),\n",
       " (59, 57),\n",
       " (59, 58),\n",
       " (59, 60),\n",
       " (59, 61),\n",
       " (59, 62),\n",
       " (59, 63),\n",
       " (59, 64),\n",
       " (60, 55),\n",
       " (60, 56),\n",
       " (60, 57),\n",
       " (60, 58),\n",
       " (60, 59),\n",
       " (60, 61),\n",
       " (60, 62),\n",
       " (60, 63),\n",
       " (60, 64),\n",
       " (60, 65),\n",
       " (61, 56),\n",
       " (61, 57),\n",
       " (61, 58),\n",
       " (61, 59),\n",
       " (61, 60),\n",
       " (61, 62),\n",
       " (61, 63),\n",
       " (61, 64),\n",
       " (61, 65),\n",
       " (61, 66),\n",
       " (62, 57),\n",
       " (62, 58),\n",
       " (62, 59),\n",
       " (62, 60),\n",
       " (62, 61),\n",
       " (62, 63),\n",
       " (62, 64),\n",
       " (62, 65),\n",
       " (62, 66),\n",
       " (62, 67),\n",
       " (63, 58),\n",
       " (63, 59),\n",
       " (63, 60),\n",
       " (63, 61),\n",
       " (63, 62),\n",
       " (63, 64),\n",
       " (63, 65),\n",
       " (63, 66),\n",
       " (63, 67),\n",
       " (63, 68),\n",
       " (64, 59),\n",
       " (64, 60),\n",
       " (64, 61),\n",
       " (64, 62),\n",
       " (64, 63),\n",
       " (64, 65),\n",
       " (64, 66),\n",
       " (64, 67),\n",
       " (64, 68),\n",
       " (64, 69),\n",
       " (65, 60),\n",
       " (65, 61),\n",
       " (65, 62),\n",
       " (65, 63),\n",
       " (65, 64),\n",
       " (65, 66),\n",
       " (65, 67),\n",
       " (65, 68),\n",
       " (65, 69),\n",
       " (65, 70),\n",
       " (66, 61),\n",
       " (66, 62),\n",
       " (66, 63),\n",
       " (66, 64),\n",
       " (66, 65),\n",
       " (66, 67),\n",
       " (66, 68),\n",
       " (66, 69),\n",
       " (66, 70),\n",
       " (66, 71),\n",
       " (67, 62),\n",
       " (67, 63),\n",
       " (67, 64),\n",
       " (67, 65),\n",
       " (67, 66),\n",
       " (67, 68),\n",
       " (67, 69),\n",
       " (67, 70),\n",
       " (67, 71),\n",
       " (67, 72),\n",
       " (68, 63),\n",
       " (68, 64),\n",
       " (68, 65),\n",
       " (68, 66),\n",
       " (68, 67),\n",
       " (68, 69),\n",
       " (68, 70),\n",
       " (68, 71),\n",
       " (68, 72),\n",
       " (68, 73),\n",
       " (69, 64),\n",
       " (69, 65),\n",
       " (69, 66),\n",
       " (69, 67),\n",
       " (69, 68),\n",
       " (69, 70),\n",
       " (69, 71),\n",
       " (69, 72),\n",
       " (69, 73),\n",
       " (69, 74),\n",
       " (70, 65),\n",
       " (70, 66),\n",
       " (70, 67),\n",
       " (70, 68),\n",
       " (70, 69),\n",
       " (70, 71),\n",
       " (70, 72),\n",
       " (70, 73),\n",
       " (70, 74),\n",
       " (70, 75),\n",
       " (71, 66),\n",
       " (71, 67),\n",
       " (71, 68),\n",
       " (71, 69),\n",
       " (71, 70),\n",
       " (71, 72),\n",
       " (71, 73),\n",
       " (71, 74),\n",
       " (71, 75),\n",
       " (71, 76),\n",
       " (72, 67),\n",
       " (72, 68),\n",
       " (72, 69),\n",
       " (72, 70),\n",
       " (72, 71),\n",
       " (72, 73),\n",
       " (72, 74),\n",
       " (72, 75),\n",
       " (72, 76),\n",
       " (72, 77),\n",
       " (73, 68),\n",
       " (73, 69),\n",
       " (73, 70),\n",
       " (73, 71),\n",
       " (73, 72),\n",
       " (73, 74),\n",
       " (73, 75),\n",
       " (73, 76),\n",
       " (73, 77),\n",
       " (73, 78),\n",
       " (74, 69),\n",
       " (74, 70),\n",
       " (74, 71),\n",
       " (74, 72),\n",
       " (74, 73),\n",
       " (74, 75),\n",
       " (74, 76),\n",
       " (74, 77),\n",
       " (74, 78),\n",
       " (74, 79),\n",
       " (75, 70),\n",
       " (75, 71),\n",
       " (75, 72),\n",
       " (75, 73),\n",
       " (75, 74),\n",
       " (75, 76),\n",
       " (75, 77),\n",
       " (75, 78),\n",
       " (75, 79),\n",
       " (75, 80),\n",
       " (76, 71),\n",
       " (76, 72),\n",
       " (76, 73),\n",
       " (76, 74),\n",
       " (76, 75),\n",
       " (76, 77),\n",
       " (76, 78),\n",
       " (76, 79),\n",
       " (76, 80),\n",
       " (76, 81),\n",
       " (77, 72),\n",
       " (77, 73),\n",
       " (77, 74),\n",
       " (77, 75),\n",
       " (77, 76),\n",
       " (77, 78),\n",
       " (77, 79),\n",
       " (77, 80),\n",
       " (77, 81),\n",
       " (77, 82),\n",
       " (78, 73),\n",
       " (78, 74),\n",
       " (78, 75),\n",
       " (78, 76),\n",
       " (78, 77),\n",
       " (78, 79),\n",
       " (78, 80),\n",
       " (78, 81),\n",
       " (78, 82),\n",
       " (78, 83),\n",
       " (79, 74),\n",
       " (79, 75),\n",
       " (79, 76),\n",
       " (79, 77),\n",
       " (79, 78),\n",
       " (79, 80),\n",
       " (79, 81),\n",
       " (79, 82),\n",
       " (79, 83),\n",
       " (79, 84),\n",
       " (80, 75),\n",
       " (80, 76),\n",
       " (80, 77),\n",
       " (80, 78),\n",
       " (80, 79),\n",
       " (80, 81),\n",
       " (80, 82),\n",
       " (80, 83),\n",
       " (80, 84),\n",
       " (80, 85),\n",
       " (81, 76),\n",
       " (81, 77),\n",
       " (81, 78),\n",
       " (81, 79),\n",
       " (81, 80),\n",
       " (81, 82),\n",
       " (81, 83),\n",
       " (81, 84),\n",
       " (81, 85),\n",
       " (81, 86),\n",
       " (82, 77),\n",
       " (82, 78),\n",
       " (82, 79),\n",
       " (82, 80),\n",
       " (82, 81),\n",
       " (82, 83),\n",
       " (82, 84),\n",
       " (82, 85),\n",
       " (82, 86),\n",
       " (82, 87),\n",
       " (83, 78),\n",
       " (83, 79),\n",
       " (83, 80),\n",
       " (83, 81),\n",
       " (83, 82),\n",
       " (83, 84),\n",
       " (83, 85),\n",
       " (83, 86),\n",
       " (83, 87),\n",
       " (83, 88),\n",
       " (84, 79),\n",
       " (84, 80),\n",
       " (84, 81),\n",
       " (84, 82),\n",
       " (84, 83),\n",
       " (84, 85),\n",
       " (84, 86),\n",
       " (84, 87),\n",
       " (84, 88),\n",
       " (84, 89),\n",
       " (85, 80),\n",
       " (85, 81),\n",
       " (85, 82),\n",
       " (85, 83),\n",
       " (85, 84),\n",
       " (85, 86),\n",
       " (85, 87),\n",
       " (85, 88),\n",
       " (85, 89),\n",
       " (85, 90),\n",
       " (86, 81),\n",
       " (86, 82),\n",
       " (86, 83),\n",
       " (86, 84),\n",
       " (86, 85),\n",
       " (86, 87),\n",
       " (86, 88),\n",
       " (86, 89),\n",
       " (86, 90),\n",
       " (86, 91),\n",
       " (87, 82),\n",
       " (87, 83),\n",
       " (87, 84),\n",
       " (87, 85),\n",
       " (87, 86),\n",
       " (87, 88),\n",
       " (87, 89),\n",
       " (87, 90),\n",
       " (87, 91),\n",
       " (87, 92),\n",
       " (88, 83),\n",
       " (88, 84),\n",
       " (88, 85),\n",
       " (88, 86),\n",
       " (88, 87),\n",
       " (88, 89),\n",
       " (88, 90),\n",
       " (88, 91),\n",
       " (88, 92),\n",
       " (88, 93),\n",
       " (89, 84),\n",
       " (89, 85),\n",
       " (89, 86),\n",
       " (89, 87),\n",
       " (89, 88),\n",
       " (89, 90),\n",
       " (89, 91),\n",
       " (89, 92),\n",
       " (89, 93),\n",
       " (89, 94),\n",
       " (90, 85),\n",
       " (90, 86),\n",
       " (90, 87),\n",
       " (90, 88),\n",
       " (90, 89),\n",
       " (90, 91),\n",
       " (90, 92),\n",
       " (90, 93),\n",
       " (90, 94),\n",
       " (90, 95),\n",
       " (91, 86),\n",
       " (91, 87),\n",
       " (91, 88),\n",
       " (91, 89),\n",
       " (91, 90),\n",
       " (91, 92),\n",
       " (91, 93),\n",
       " (91, 94),\n",
       " (91, 95),\n",
       " (91, 96),\n",
       " (92, 87),\n",
       " (92, 88),\n",
       " (92, 89),\n",
       " (92, 90),\n",
       " (92, 91),\n",
       " (92, 93),\n",
       " (92, 94),\n",
       " (92, 95),\n",
       " (92, 96),\n",
       " (92, 97),\n",
       " (93, 88),\n",
       " (93, 89),\n",
       " (93, 90),\n",
       " (93, 91),\n",
       " (93, 92),\n",
       " (93, 94),\n",
       " (93, 95),\n",
       " (93, 96),\n",
       " (93, 97),\n",
       " (93, 98),\n",
       " (94, 89),\n",
       " (94, 90),\n",
       " (94, 91),\n",
       " (94, 92),\n",
       " (94, 93),\n",
       " (94, 95),\n",
       " (94, 96),\n",
       " (94, 97),\n",
       " (94, 98),\n",
       " (94, 99),\n",
       " (95, 90),\n",
       " (95, 91),\n",
       " (95, 92),\n",
       " (95, 93),\n",
       " (95, 94),\n",
       " (95, 96),\n",
       " (95, 97),\n",
       " (95, 98),\n",
       " (95, 99),\n",
       " (95, 100),\n",
       " (96, 91),\n",
       " (96, 92),\n",
       " (96, 93),\n",
       " (96, 94),\n",
       " (96, 95),\n",
       " (96, 97),\n",
       " (96, 98),\n",
       " (96, 99),\n",
       " (96, 100),\n",
       " (96, 101),\n",
       " (97, 92),\n",
       " (97, 93),\n",
       " (97, 94),\n",
       " (97, 95),\n",
       " (97, 96),\n",
       " (97, 98),\n",
       " (97, 99),\n",
       " (97, 100),\n",
       " (97, 101),\n",
       " (97, 102),\n",
       " (98, 93),\n",
       " (98, 94),\n",
       " (98, 95),\n",
       " (98, 96),\n",
       " (98, 97),\n",
       " (98, 99),\n",
       " (98, 100),\n",
       " (98, 101),\n",
       " (98, 102),\n",
       " (98, 103),\n",
       " (99, 94),\n",
       " (99, 95),\n",
       " (99, 96),\n",
       " (99, 97),\n",
       " (99, 98),\n",
       " (99, 100),\n",
       " (99, 101),\n",
       " (99, 102),\n",
       " (99, 103),\n",
       " (99, 104),\n",
       " (100, 95),\n",
       " (100, 96),\n",
       " (100, 97),\n",
       " (100, 98),\n",
       " (100, 99),\n",
       " (100, 101),\n",
       " (100, 102),\n",
       " (100, 103),\n",
       " (100, 104),\n",
       " (100, 105),\n",
       " (101, 96),\n",
       " (101, 97),\n",
       " (101, 98),\n",
       " (101, 99),\n",
       " (101, 100),\n",
       " (101, 102),\n",
       " (101, 103),\n",
       " (101, 104),\n",
       " (101, 105),\n",
       " (101, 106),\n",
       " (102, 97),\n",
       " (102, 98),\n",
       " (102, 99),\n",
       " (102, 100),\n",
       " (102, 101),\n",
       " (102, 103),\n",
       " (102, 104),\n",
       " (102, 105),\n",
       " (102, 106),\n",
       " (102, 107),\n",
       " (103, 98),\n",
       " (103, 99),\n",
       " (103, 100),\n",
       " (103, 101),\n",
       " (103, 102),\n",
       " (103, 104),\n",
       " (103, 105),\n",
       " (103, 106),\n",
       " (103, 107),\n",
       " (103, 108),\n",
       " (104, 99),\n",
       " (104, 100),\n",
       " (104, 101),\n",
       " (104, 102),\n",
       " (104, 103),\n",
       " (104, 105),\n",
       " (104, 106),\n",
       " (104, 107),\n",
       " (104, 108),\n",
       " (104, 109),\n",
       " ...]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from nlptext.utils.grain import generate_batch_idx\n",
    "from nlpembed.utils.batch import generate_batch_idx\n",
    "\n",
    "maxlen = BasicObject.TOKEN['length']\n",
    "\n",
    "BATCH = dict(\n",
    "    skip_window = 5,\n",
    "    batch_token_num = 1000,\n",
    "    maxlen = maxlen,\n",
    "    left2right = 'tgt-ctx', # 'ctx-tgt', #\n",
    "    size2size  = '1-1' , # 'All-1' (for ctx-tgt only) and '1-All' (for tgt-ctx only)\n",
    "    tgtInctx   = False,\n",
    "    # tgt_start_idx = skip_window,\n",
    ")\n",
    "\n",
    "if BATCH['size2size'] == '1-1':\n",
    "    BATCH['batch_size'] = BATCH['batch_token_num'] * (BATCH['skip_window']*2 + int(BATCH['tgtInctx']))\n",
    "else:\n",
    "    BATCH['batch_size'] = BATCH['batch_token_num']\n",
    "    \n",
    "    \n",
    "print(BATCH)\n",
    "tgt_start_idx = BATCH['skip_window']\n",
    "left, right, data_index = generate_batch_idx(tgt_start_idx,  **BATCH)\n",
    "\n",
    "list(zip(left, right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   5,    5,    5, ..., 1004, 1004, 1004])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "CH = {'token': {'Max_Ngram': 1},\n",
    " 'char': {'Max_Ngram': 1, 'end_grain': False},\n",
    " 'basic': {'Max_Ngram': 2, 'end_grain': False},\n",
    " 'medical': {'Max_Ngram': 2, 'end_grain': False},\n",
    " 'radical': {'Max_Ngram': 2, 'end_grain': False},\n",
    " 'subcomp': {'Max_Ngram': 3, 'end_grain': True},\n",
    " 'stroke': {'Max_Ngram': 5, 'end_grain': True},\n",
    "  'pos': {'Max_Ngram': 1, 'end_grain': False, 'tagScheme': 'BIO'},\n",
    "     }\n",
    "\n",
    "channel = 'stroke'\n",
    "cs = CH[channel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get LookUp Table for Channel: stroke5e\n",
      "(10000, 1, 105) (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from nlptext.token import Token\n",
    "\n",
    "\n",
    "def transfer_batch(batch_idx):\n",
    "    if len(batch_idx.shape) == 2:\n",
    "        elen, tkn = batch_idx.shape\n",
    "        batch_idx = np.reshape(batch_idx, (elen*tkn))# .shape\n",
    "    else:\n",
    "        elen, tkn = batch_idx.shape[0], 1\n",
    "    batch = np.array([Token(token_idx) for token_idx in batch_idx]).reshape(elen, tkn)\n",
    "    return batch\n",
    "    \n",
    "batch = transfer_batch(left)\n",
    "elen, tkn = batch.shape\n",
    "batch = np.reshape(batch, (elen*tkn))# .shape\n",
    "Info_Leng = [tk.getGrainTensor(channel, **cs)  for tk in batch]\n",
    "channelLeng = np.array([info_leng[1] for info_leng in Info_Leng], dtype='float32')\n",
    "maxGrainLeng = int(np.max(channelLeng))\n",
    "\n",
    "channelInfo = [info_leng[0] for info_leng in Info_Leng]\n",
    "\n",
    "channelInfo_Final =np.zeros([len(channelInfo), maxGrainLeng], dtype=int)\n",
    "for idx, info in enumerate(channelInfo):\n",
    "    channelInfo_Final[idx, :len(info)] = channelInfo[idx]\n",
    "\n",
    "channelInfo_Final = channelInfo_Final.reshape(elen, tkn, maxGrainLeng)\n",
    "channelLeng = channelLeng.reshape(elen, tkn)\n",
    "\n",
    "print(channelInfo_Final.shape, channelLeng.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1, 105) (1000, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch = transder_batch(right)\n",
    "elen, tkn = batch.shape\n",
    "batch = np.reshape(batch, (elen*tkn))# .shape\n",
    "Info_Leng = [tk.getGrainTensor(channel, **cs)  for tk in batch]\n",
    "channelLeng = np.array([info_leng[1] for info_leng in Info_Leng], dtype='float32')\n",
    "maxGrainLeng = int(np.max(channelLeng))\n",
    "\n",
    "channelInfo = [info_leng[0] for info_leng in Info_Leng]\n",
    "\n",
    "channelInfo_Final =np.zeros([len(channelInfo), maxGrainLeng], dtype=int)\n",
    "for idx, info in enumerate(channelInfo):\n",
    "    channelInfo_Final[idx, :len(info)] = channelInfo[idx]\n",
    "\n",
    "channelInfo_Final = channelInfo_Final.reshape(elen, tkn, maxGrainLeng)\n",
    "channelLeng = channelLeng.reshape(elen, tkn)\n",
    "\n",
    "print(channelInfo_Final.shape, channelLeng.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORPUS\tread from pickle file : data/LuohuCorpus/char/Token3546/Pyramid/CORPUS.p\n",
      "CORPUS\tthe length of it is   : 1\n",
      "FOLDER\tread from pickle file : data/LuohuCorpus/char/Token3546/Pyramid/FOLDER.p\n",
      "FOLDER\tthe length of it is   : 44\n",
      "TEXT\tread from pickle file : data/LuohuCorpus/char/Token3546/Pyramid/TEXT.p\n",
      "TEXT\tthe length of it is   : 227876\n",
      "SENT\tread from pickle file : data/LuohuCorpus/char/Token3546/Pyramid/SENT.p\n",
      "SENT\tthe length of it is   : 1213151\n",
      "TOKEN\tread from pickle file : data/LuohuCorpus/char/Token3546/Pyramid/TOKEN.p\n",
      "TOKEN\tthe length of it is   : 36760202\n",
      "**************************************** \n",
      "\n",
      "token\tread from pickle file : data/LuohuCorpus/char/Token3546/GrainUnique/token.p\n",
      "token\tthe length of it is   : 3546\n",
      "**************************************** \n",
      "\n",
      "Deal with the Channel: token\n",
      "Current Channel is        \t token\n",
      "Current Channel Max_Ngram \t 1\n",
      "Deal with the Channel: char\n",
      "Current Channel is        \t char\n",
      "Current Channel Max_Ngram \t 1\n",
      "Deal with the Channel: basic\n",
      "Current Channel is        \t basic\n",
      "Current Channel Max_Ngram \t 1\n",
      "Deal with the Channel: medical\n",
      "Current Channel is        \t medical\n",
      "Current Channel Max_Ngram \t 1\n",
      "Deal with the Channel: radical\n",
      "Current Channel is        \t radical\n",
      "Current Channel Max_Ngram \t 1\n",
      "Deal with the Channel: subcomp\n",
      "Current Channel is        \t subcomp\n",
      "Current Channel Max_Ngram \t 3\n",
      "Deal with the Channel: stroke\n",
      "Current Channel is        \t stroke\n",
      "Current Channel Max_Ngram \t 5\n",
      "Deal with the Channel: pos\n",
      "Current Channel is        \t pos\n",
      "Current Channel Max_Ngram \t 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pprint import pprint\n",
    "from nlptext.base import BasicObject\n",
    "\n",
    "CHANNEL_SETTINGS_TEMPLATE = {\n",
    "    # CTX_IND\n",
    "    'token':   {'use': True, 'Max_Ngram': 1,},\n",
    "    'char':    {'use': True,'Max_Ngram': 1, 'end_grain': False},\n",
    "    'basic':   {'use': True,'Max_Ngram': 1, 'end_grain': False},\n",
    "    'medical': {'use': True,'Max_Ngram': 1, 'end_grain': False},\n",
    "    'radical': {'use': True,'Max_Ngram': 1, 'end_grain': False},\n",
    "    'subcomp': {'use': True,'Max_Ngram': 3, 'end_grain': True},\n",
    "    'stroke':  {'use': True,'Max_Ngram': 5, 'end_grain': True},\n",
    "    # CTX_DEP\n",
    "    'pos':     {'use': True,'Max_Ngram': 1, 'end_grain': False, 'tagScheme':   'BIO',},\n",
    "    # ANNO\n",
    "    'annoR':   {'use': False,'Max_Ngram': 1, 'end_grain': False, 'tagScheme':   'BIO',},\n",
    "    'annoE':   {'use': False,'Max_Ngram': 1, 'end_grain': False, 'tagScheme':   'BIO',},\n",
    "}\n",
    "\n",
    "# Path2Pyramid = 'data/boson/char/Token3870/Pyramid/'\n",
    "# Path2LGUnique = 'data/boson/char/Token3870/GrainUnique/'\n",
    "\n",
    "\n",
    "\n",
    "Path2Pyramid  = 'data/LuohuCorpus/char/Token3546/Pyramid/'\n",
    "Path2LGUnique = 'data/LuohuCorpus/char/Token3546/GrainUnique/'\n",
    "\n",
    "\n",
    "\n",
    "BasicObject.INIT_FROM_PICKLE(Path2Pyramid, Path2LGUnique)\n",
    "\n",
    "BasicObject.BUILD_GRAIN_UNI_AND_LOOKUP(CHANNEL_SETTINGS_TEMPLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['token',\n",
       " 'char',\n",
       " 'basic',\n",
       " 'medical',\n",
       " 'radical',\n",
       " 'subcomp3e',\n",
       " 'stroke5e',\n",
       " 'pos']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in BasicObject.GRAIN_UNI['data/LuohuCorpus/char/Token3546']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'skip_window': 5, 'batch_token_num': 1000, 'maxlen': 36760202, 'left2right': 'ctx-tgt', 'size2size': 'All-1', 'tgtInctx': True, 'batch_size': 1000}\n",
      "0:00:00.269599\n",
      "0:00:00.277100\n",
      "0:00:00.251736\n",
      "0:00:00.232014\n",
      "0:00:00.240076\n",
      "0:00:00.234383\n",
      "0:00:00.252401\n",
      "0:00:00.237043\n",
      "0:00:00.254137\n",
      "0:00:00.230106\n"
     ]
    }
   ],
   "source": [
    "from nlpembed.utils.batch import generate_batch_idx, transfer_batch, getTokenBatchInfo\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "maxlen = BasicObject.TOKEN['length']\n",
    "\n",
    "BATCH = dict(\n",
    "    skip_window = 5,\n",
    "    batch_token_num = 1000,\n",
    "    maxlen = maxlen,\n",
    "    left2right = 'ctx-tgt', #'tgt-ctx', #\n",
    "    size2size  = 'All-1' , # 'All-1' (for ctx-tgt only) and '1-All' (for tgt-ctx only)\n",
    "    tgtInctx   = True,\n",
    "    # tgt_start_idx = skip_window,\n",
    ")\n",
    "\n",
    "if BATCH['size2size'] == '1-1':\n",
    "    BATCH['batch_size'] = BATCH['batch_token_num'] * (BATCH['skip_window']*2 + int(BATCH['tgtInctx']))\n",
    "else:\n",
    "    BATCH['batch_size'] = BATCH['batch_token_num']\n",
    "    \n",
    "    \n",
    "print(BATCH)\n",
    "tgt_start_idx = BATCH['skip_window']\n",
    "\n",
    "\n",
    "CH = {'token': {'Max_Ngram': 1},\n",
    "    #  'char': {'Max_Ngram': 1, 'end_grain': False},\n",
    "     'basic': {'Max_Ngram': 1, 'end_grain': False},\n",
    "     'medical': {'Max_Ngram': 1, 'end_grain': False},\n",
    "     'radical': {'Max_Ngram': 1, 'end_grain': False},\n",
    "     'subcomp': {'Max_Ngram': 3, 'end_grain': True},\n",
    "     'stroke': {'Max_Ngram': 5, 'end_grain': True},\n",
    "      'pos': {'Max_Ngram': 1, 'end_grain': False, 'tagScheme': 'BIO'},\n",
    "}\n",
    "\n",
    "num_steps = 10\n",
    "\n",
    "tgt_start_idx = tgt_start_idx = BATCH['skip_window']\n",
    "for step in range(1, num_steps + 1):\n",
    "    T_total_start = datetime.now()\n",
    "    T_batch_start = T_total_start\n",
    "\n",
    "    # Step1: generate batch data\n",
    "    batch_left, batch_right, tgt_start_idx = generate_batch_idx(tgt_start_idx,  **BATCH)\n",
    "    # print(batch_left)\n",
    "    # print(batch_right)\n",
    "    batch_left = transfer_batch(batch_left)\n",
    "    batch_Left_Channels_Info_Leng = {ch: getTokenBatchInfo(batch_left, ch, **cs) for ch, cs in CH.items()}\n",
    "    batch_Left_Channels_Info = {ch:v[0] for ch, v in batch_Left_Channels_Info_Leng.items()}\n",
    "    batch_Left_Channels_Leng = {ch:v[1] for ch, v in batch_Left_Channels_Info_Leng.items()}\n",
    "\n",
    "    # batch_right = [Token(tk_idx) for tk_idx in batch_right]\n",
    "    \n",
    "    ##############################################\n",
    "    batch_right = transfer_batch(batch_right)\n",
    "    batch_Right_Channels_Info_Leng = {'token': getTokenBatchInfo(batch_right, 'token')}\n",
    "    batch_Right_Channels_Info = {ch:v[0] for ch, v in batch_Right_Channels_Info_Leng.items()}\n",
    "    batch_Right_Channels_Leng = {ch:v[1] for ch, v in batch_Right_Channels_Info_Leng.items()}\n",
    "\n",
    "\n",
    "#     # Step2: feed the batch data to feed_dict\n",
    "#     feed_dict = {}\n",
    "\n",
    "#     for ch in TVC_left:\n",
    "#         feed_dict[Batch_Left_channelInfos[ch] ] = batch_Left_Channels_Info[ch]\n",
    "#         feed_dict[Batch_Left_channelLengs[ch] ] = batch_Left_Channels_Leng[ch]\n",
    "#     for ch in TVC_right:\n",
    "#         feed_dict[Batch_Right_channelInfos[ch]] = batch_Right_Channels_Info[ch]\n",
    "#         feed_dict[Batch_Right_channelLengs[ch]] = batch_Right_Channels_Leng[ch]\n",
    "\n",
    "\n",
    "    T_batch_end = datetime.now()\n",
    "    print(T_batch_end- T_batch_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: None,\n",
       " 1: None,\n",
       " 2: None,\n",
       " 3: None,\n",
       " 4: None,\n",
       " 5: None,\n",
       " 6: None,\n",
       " 7: None,\n",
       " 8: None,\n",
       " 9: None}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'3': 4, '1': 'a', '2': 'b'}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = {'1': 'a', '2':'b'}\n",
    "\n",
    "d = {'3':4, **a}\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "80\n",
      "50\n",
      "60\n",
      "70\n",
      "90\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "def func(x, **ch):\n",
    "    print(x*10) \n",
    "\n",
    "d = {}\n",
    "for i in range(10):\n",
    "    p = multiprocessing.Process(target = func, args = (i,))\n",
    "    d[i] = p\n",
    "    p.start()\n",
    "    \n",
    "for i, p in d.items():\n",
    "    \n",
    "    d[i] = p.join()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1, 1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_Right_Channels_Info['token'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 11, 75)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_Left_Channels_Info['stroke'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 11, 1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_Left_Channels_Info['token'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<tk 酸 >],\n",
       "       [<tk 、 >],\n",
       "       [<tk 烧 >],\n",
       "       [<tk 心 >],\n",
       "       [<tk , >],\n",
       "       [<tk 口 >],\n",
       "       [<tk 干 >],\n",
       "       [<tk 、 >],\n",
       "       [<tk 口 >],\n",
       "       [<tk 苦 >],\n",
       "       [<tk , >],\n",
       "       [<tk 无 >],\n",
       "       [<tk 发 >],\n",
       "       [<tk 热 >],\n",
       "       [<tk 、 >],\n",
       "       [<tk 畏 >],\n",
       "       [<tk 寒 >],\n",
       "       [<tk , >],\n",
       "       [<tk 无 >],\n",
       "       [<tk 厌 >],\n",
       "       [<tk 油 >],\n",
       "       [<tk 等 >],\n",
       "       [<tk 不 >],\n",
       "       [<tk 适 >],\n",
       "       [<tk , >],\n",
       "       [<tk 为 >],\n",
       "       [<tk 求 >],\n",
       "       [<tk 系 >],\n",
       "       [<tk 统 >],\n",
       "       [<tk 诊 >],\n",
       "       [<tk 治 >],\n",
       "       [<tk 遂 >],\n",
       "       [<tk 来 >],\n",
       "       [<tk 我 >],\n",
       "       [<tk 院 >],\n",
       "       [<tk 就 >],\n",
       "       [<tk 诊 >],\n",
       "       [<tk , >],\n",
       "       [<tk 由 >],\n",
       "       [<tk 门 >],\n",
       "       [<tk 诊 >],\n",
       "       [<tk 收 >],\n",
       "       [<tk 住 >],\n",
       "       [<tk 我 >],\n",
       "       [<tk 科 >],\n",
       "       [<tk 。 >],\n",
       "       [<tk 现 >],\n",
       "       [<tk 病 >],\n",
       "       [<tk 史 >],\n",
       "       [<tk : >],\n",
       "       [<tk 6 >],\n",
       "       [<tk 天 >],\n",
       "       [<tk 前 >],\n",
       "       [<tk 无 >],\n",
       "       [<tk 明 >],\n",
       "       [<tk 显 >],\n",
       "       [<tk 诱 >],\n",
       "       [<tk 因 >],\n",
       "       [<tk 出 >],\n",
       "       [<tk 现 >],\n",
       "       [<tk 右 >],\n",
       "       [<tk 侧 >],\n",
       "       [<tk 咽 >],\n",
       "       [<tk 喉 >],\n",
       "       [<tk 痛 >],\n",
       "       [<tk , >],\n",
       "       [<tk 吞 >],\n",
       "       [<tk 咽 >],\n",
       "       [<tk 时 >],\n",
       "       [<tk 咽 >],\n",
       "       [<tk 痛 >],\n",
       "       [<tk 加 >],\n",
       "       [<tk 剧 >],\n",
       "       [<tk , >],\n",
       "       [<tk 无 >],\n",
       "       [<tk 畏 >],\n",
       "       [<tk 寒 >],\n",
       "       [<tk 、 >],\n",
       "       [<tk 发 >],\n",
       "       [<tk 热 >],\n",
       "       [<tk , >],\n",
       "       [<tk 无 >],\n",
       "       [<tk 咳 >],\n",
       "       [<tk 嗽 >],\n",
       "       [<tk 、 >],\n",
       "       [<tk 咳 >],\n",
       "       [<tk 痰 >],\n",
       "       [<tk 、 >],\n",
       "       [<tk 气 >],\n",
       "       [<tk 促 >],\n",
       "       [<tk , >],\n",
       "       [<tk 无 >],\n",
       "       [<tk 鼻 >],\n",
       "       [<tk 塞 >],\n",
       "       [<tk 、 >],\n",
       "       [<tk 流 >],\n",
       "       [<tk 涕 >],\n",
       "       [<tk 、 >],\n",
       "       [<tk 耳 >],\n",
       "       [<tk 漏 >],\n",
       "       [<tk , >],\n",
       "       [<tk 自 >],\n",
       "       [<tk 行 >],\n",
       "       [<tk 口 >],\n",
       "       [<tk 服 >],\n",
       "       [<tk 抗 >],\n",
       "       [<tk 生 >],\n",
       "       [<tk 素 >],\n",
       "       [<tk , >],\n",
       "       [<tk 右 >],\n",
       "       [<tk 侧 >],\n",
       "       [<tk 咽 >],\n",
       "       [<tk 喉 >],\n",
       "       [<tk 痛 >],\n",
       "       [<tk 逐 >],\n",
       "       [<tk 渐 >],\n",
       "       [<tk 加 >],\n",
       "       [<tk 重 >],\n",
       "       [<tk , >],\n",
       "       [<tk 1 >],\n",
       "       [<tk 天 >],\n",
       "       [<tk 前 >],\n",
       "       [<tk 出 >],\n",
       "       [<tk 现 >],\n",
       "       [<tk 张 >],\n",
       "       [<tk 口 >],\n",
       "       [<tk 困 >],\n",
       "       [<tk 难 >],\n",
       "       [<tk , >],\n",
       "       [<tk 不 >],\n",
       "       [<tk 能 >],\n",
       "       [<tk 进 >],\n",
       "       [<tk 食 >],\n",
       "       [<tk , >],\n",
       "       [<tk 急 >],\n",
       "       [<tk 来 >],\n",
       "       [<tk 我 >],\n",
       "       [<tk 院 >],\n",
       "       [<tk 就 >],\n",
       "       [<tk 诊 >],\n",
       "       [<tk , >],\n",
       "       [<tk 急 >],\n",
       "       [<tk 诊 >],\n",
       "       [<tk 以 >],\n",
       "       [<tk “ >],\n",
       "       [<tk 右 >],\n",
       "       [<tk 侧 >],\n",
       "       [<tk 扁 >],\n",
       "       [<tk 桃 >],\n",
       "       [<tk 体 >],\n",
       "       [<tk 周 >],\n",
       "       [<tk 脓 >],\n",
       "       [<tk 肿 >],\n",
       "       [<tk ” >],\n",
       "       [<tk 收 >],\n",
       "       [<tk 住 >],\n",
       "       [<tk 院 >],\n",
       "       [<tk 。 >],\n",
       "       [<tk 病 >],\n",
       "       [<tk 程 >],\n",
       "       [<tk 中 >],\n",
       "       [<tk , >],\n",
       "       [<tk 患 >],\n",
       "       [<tk 者 >],\n",
       "       [<tk 精 >],\n",
       "       [<tk 神 >],\n",
       "       [<tk 欠 >],\n",
       "       [<tk 佳 >],\n",
       "       [<tk , >],\n",
       "       [<tk 睡 >],\n",
       "       [<tk 眠 >],\n",
       "       [<tk 、 >],\n",
       "       [<tk 食 >],\n",
       "       [<tk 欲 >],\n",
       "       [<tk 一 >],\n",
       "       [<tk 般 >],\n",
       "       [<tk , >],\n",
       "       [<tk 大 >],\n",
       "       [<tk 小 >],\n",
       "       [<tk 便 >],\n",
       "       [<tk 正 >],\n",
       "       [<tk 常 >],\n",
       "       [<tk , >],\n",
       "       [<tk 体 >],\n",
       "       [<tk 重 >],\n",
       "       [<tk 无 >],\n",
       "       [<tk 明 >],\n",
       "       [<tk 显 >],\n",
       "       [<tk 变 >],\n",
       "       [<tk 化 >],\n",
       "       [<tk 。 >],\n",
       "       [<tk 现 >],\n",
       "       [<tk 病 >],\n",
       "       [<tk 史 >],\n",
       "       [<tk : >],\n",
       "       [<tk 患 >],\n",
       "       [<tk 者 >],\n",
       "       [<tk 1 >],\n",
       "       [<tk 月 >],\n",
       "       [<tk 前 >],\n",
       "       [<tk 发 >],\n",
       "       [<tk 现 >],\n",
       "       [<tk 肛 >],\n",
       "       [<tk 旁 >],\n",
       "       [<tk 赘 >],\n",
       "       [<tk 生 >],\n",
       "       [<tk 物 >],\n",
       "       [<tk , >],\n",
       "       [<tk 无 >],\n",
       "       [<tk 红 >],\n",
       "       [<tk 肿 >],\n",
       "       [<tk 、 >],\n",
       "       [<tk 疼 >],\n",
       "       [<tk 痛 >],\n",
       "       [<tk , >],\n",
       "       [<tk 无 >],\n",
       "       [<tk 肛 >],\n",
       "       [<tk 门 >],\n",
       "       [<tk 瘙 >],\n",
       "       [<tk 痒 >],\n",
       "       [<tk 不 >],\n",
       "       [<tk 适 >],\n",
       "       [<tk , >],\n",
       "       [<tk 无 >],\n",
       "       [<tk 肛 >],\n",
       "       [<tk 周 >],\n",
       "       [<tk 分 >],\n",
       "       [<tk 泌 >],\n",
       "       [<tk 物 >],\n",
       "       [<tk , >],\n",
       "       [<tk 之 >],\n",
       "       [<tk 后 >],\n",
       "       [<tk 赘 >],\n",
       "       [<tk 生 >],\n",
       "       [<tk 物 >],\n",
       "       [<tk 逐 >],\n",
       "       [<tk 渐 >],\n",
       "       [<tk 长 >],\n",
       "       [<tk 大 >],\n",
       "       [<tk , >],\n",
       "       [<tk 现 >],\n",
       "       [<tk 为 >],\n",
       "       [<tk 寻 >],\n",
       "       [<tk 求 >],\n",
       "       [<tk 进 >],\n",
       "       [<tk 一 >],\n",
       "       [<tk 步 >],\n",
       "       [<tk 治 >],\n",
       "       [<tk 疗 >],\n",
       "       [<tk 前 >],\n",
       "       [<tk 来 >],\n",
       "       [<tk 我 >],\n",
       "       [<tk 科 >],\n",
       "       [<tk 就 >],\n",
       "       [<tk 诊 >],\n",
       "       [<tk , >],\n",
       "       [<tk 门 >],\n",
       "       [<tk 诊 >],\n",
       "       [<tk 拟 >],\n",
       "       [<tk ' >],\n",
       "       [<tk 肛 >],\n",
       "       [<tk 门 >],\n",
       "       [<tk 尖 >],\n",
       "       [<tk 锐 >],\n",
       "       [<tk 湿 >],\n",
       "       [<tk 疣 >],\n",
       "       [<tk ' >],\n",
       "       [<tk 收 >],\n",
       "       [<tk 入 >],\n",
       "       [<tk 院 >],\n",
       "       [<tk 。 >],\n",
       "       [<tk 患 >],\n",
       "       [<tk 者 >],\n",
       "       [<tk 发 >],\n",
       "       [<tk 病 >],\n",
       "       [<tk 以 >],\n",
       "       [<tk 来 >],\n",
       "       [<tk 无 >],\n",
       "       [<tk 畏 >],\n",
       "       [<tk 寒 >],\n",
       "       [<tk 、 >],\n",
       "       [<tk 发 >],\n",
       "       [<tk 热 >],\n",
       "       [<tk 、 >],\n",
       "       [<tk 腹 >],\n",
       "       [<tk 胀 >],\n",
       "       [<tk 、 >],\n",
       "       [<tk 腹 >],\n",
       "       [<tk 痛 >],\n",
       "       [<tk 等 >],\n",
       "       [<tk 不 >],\n",
       "       [<tk 适 >],\n",
       "       [<tk , >],\n",
       "       [<tk 精 >],\n",
       "       [<tk 神 >],\n",
       "       [<tk 一 >],\n",
       "       [<tk 般 >],\n",
       "       [<tk , >],\n",
       "       [<tk 食 >],\n",
       "       [<tk 欲 >],\n",
       "       [<tk 正 >],\n",
       "       [<tk 常 >],\n",
       "       [<tk , >],\n",
       "       [<tk 睡 >],\n",
       "       [<tk 眠 >],\n",
       "       [<tk 正 >],\n",
       "       [<tk 常 >],\n",
       "       [<tk , >],\n",
       "       [<tk 大 >],\n",
       "       [<tk 便 >],\n",
       "       [<tk 通 >],\n",
       "       [<tk 畅 >],\n",
       "       [<tk , >],\n",
       "       [<tk 小 >],\n",
       "       [<tk 便 >],\n",
       "       [<tk 正 >],\n",
       "       [<tk 常 >],\n",
       "       [<tk , >],\n",
       "       [<tk 体 >],\n",
       "       [<tk 重 >],\n",
       "       [<tk 无 >],\n",
       "       [<tk 变 >],\n",
       "       [<tk 化 >],\n",
       "       [<tk 。 >],\n",
       "       [<tk 现 >],\n",
       "       [<tk 病 >],\n",
       "       [<tk 史 >],\n",
       "       [<tk : >],\n",
       "       [<tk 患 >],\n",
       "       [<tk 者 >],\n",
       "       [<tk 孕 >],\n",
       "       [<tk 2 >],\n",
       "       [<tk 产 >],\n",
       "       [<tk 0 >],\n",
       "       [<tk , >],\n",
       "       [<tk 平 >],\n",
       "       [<tk 素 >],\n",
       "       [<tk 月 >],\n",
       "       [<tk 经 >],\n",
       "       [<tk 不 >],\n",
       "       [<tk 规 >],\n",
       "       [<tk 律 >],\n",
       "       [<tk , >],\n",
       "       [<tk 末 >],\n",
       "       [<tk 次 >],\n",
       "       [<tk 月 >],\n",
       "       [<tk 经 >],\n",
       "       [<tk 2 >],\n",
       "       [<tk 0 >],\n",
       "       [<tk 1 >],\n",
       "       [<tk 7 >],\n",
       "       [<tk 年 >],\n",
       "       [<tk 7 >],\n",
       "       [<tk 月 >],\n",
       "       [<tk 4 >],\n",
       "       [<tk 日 >],\n",
       "       [<tk , >],\n",
       "       [<tk 7 >],\n",
       "       [<tk 月 >],\n",
       "       [<tk 1 >],\n",
       "       [<tk 8 >],\n",
       "       [<tk 日 >],\n",
       "       [<tk 行 >],\n",
       "       [<tk 胚 >],\n",
       "       [<tk 胎 >],\n",
       "       [<tk 植 >],\n",
       "       [<tk 入 >],\n",
       "       [<tk 术 >],\n",
       "       [<tk , >],\n",
       "       [<tk 术 >],\n",
       "       [<tk 后 >],\n",
       "       [<tk 第 >],\n",
       "       [<tk 9 >],\n",
       "       [<tk 天 >],\n",
       "       [<tk 查 >],\n",
       "       [<tk 尿 >],\n",
       "       [<tk 妊 >],\n",
       "       [<tk 娠 >],\n",
       "       [<tk 试 >],\n",
       "       [<tk 验 >],\n",
       "       [<tk 阳 >],\n",
       "       [<tk 性 >],\n",
       "       [<tk , >],\n",
       "       [<tk 术 >],\n",
       "       [<tk 后 >],\n",
       "       [<tk 常 >],\n",
       "       [<tk 规 >],\n",
       "       [<tk 使 >],\n",
       "       [<tk 用 >],\n",
       "       [<tk 黄 >],\n",
       "       [<tk 体 >],\n",
       "       [<tk 酮 >],\n",
       "       [<tk 至 >],\n",
       "       [<tk 孕 >],\n",
       "       [<tk 3 >],\n",
       "       [<tk 月 >],\n",
       "       [<tk , >],\n",
       "       [<tk 9 >],\n",
       "       [<tk 月 >],\n",
       "       [<tk 2 >],\n",
       "       [<tk 5 >],\n",
       "       [<tk 日 >],\n",
       "       [<tk 查 >],\n",
       "       [<tk B >],\n",
       "       [<tk 超 >],\n",
       "       [<tk 示 >],\n",
       "       [<tk : >],\n",
       "       [<tk 宫 >],\n",
       "       [<tk 内 >],\n",
       "       [<tk 妊 >],\n",
       "       [<tk 娠 >],\n",
       "       [<tk 双 >],\n",
       "       [<tk 活 >],\n",
       "       [<tk 胎 >],\n",
       "       [<tk ( >],\n",
       "       [<tk 双 >],\n",
       "       [<tk 绒 >],\n",
       "       [<tk 双 >],\n",
       "       [<tk 羊 >],\n",
       "       [<tk ) >],\n",
       "       [<tk , >],\n",
       "       [<tk 分 >],\n",
       "       [<tk 别 >],\n",
       "       [<tk 孕 >],\n",
       "       [<tk 约 >],\n",
       "       [<tk 1 >],\n",
       "       [<tk 2 >],\n",
       "       [<tk 周 >],\n",
       "       [<tk 6 >],\n",
       "       [<tk 天 >],\n",
       "       [<tk 大 >],\n",
       "       [<tk 小 >],\n",
       "       [<tk , >],\n",
       "       [<tk 1 >],\n",
       "       [<tk 2 >],\n",
       "       [<tk 周 >],\n",
       "       [<tk 4 >],\n",
       "       [<tk 天 >],\n",
       "       [<tk 大 >],\n",
       "       [<tk 小 >],\n",
       "       [<tk , >],\n",
       "       [<tk 据 >],\n",
       "       [<tk 此 >],\n",
       "       [<tk 推 >],\n",
       "       [<tk 测 >],\n",
       "       [<tk 预 >],\n",
       "       [<tk 产 >],\n",
       "       [<tk 期 >],\n",
       "       [<tk 2 >],\n",
       "       [<tk 0 >],\n",
       "       [<tk 1 >],\n",
       "       [<tk 8 >],\n",
       "       [<tk 年 >],\n",
       "       [<tk 4 >],\n",
       "       [<tk 月 >],\n",
       "       [<tk 1 >],\n",
       "       [<tk 1 >],\n",
       "       [<tk 日 >],\n",
       "       [<tk 。 >],\n",
       "       [<tk 停 >],\n",
       "       [<tk 经 >],\n",
       "       [<tk 4 >],\n",
       "       [<tk 0 >],\n",
       "       [<tk 余 >],\n",
       "       [<tk 天 >],\n",
       "       [<tk 有 >],\n",
       "       [<tk 恶 >],\n",
       "       [<tk 心 >],\n",
       "       [<tk 、 >],\n",
       "       [<tk 食 >],\n",
       "       [<tk 欲 >],\n",
       "       [<tk 不 >],\n",
       "       [<tk 振 >],\n",
       "       [<tk 、 >],\n",
       "       [<tk 晨 >],\n",
       "       [<tk 起 >],\n",
       "       [<tk 呕 >],\n",
       "       [<tk 吐 >],\n",
       "       [<tk 等 >],\n",
       "       [<tk 早 >],\n",
       "       [<tk 孕 >],\n",
       "       [<tk 反 >],\n",
       "       [<tk 应 >],\n",
       "       [<tk , >],\n",
       "       [<tk 孕 >],\n",
       "       [<tk 4 >],\n",
       "       [<tk 月 >],\n",
       "       [<tk 自 >],\n",
       "       [<tk 行 >],\n",
       "       [<tk 消 >],\n",
       "       [<tk 失 >],\n",
       "       [<tk , >],\n",
       "       [<tk 孕 >],\n",
       "       [<tk 4 >],\n",
       "       [<tk + >],\n",
       "       [<tk 月 >],\n",
       "       [<tk 自 >],\n",
       "       [<tk 觉 >],\n",
       "       [<tk 胎 >],\n",
       "       [<tk 动 >],\n",
       "       [<tk 至 >],\n",
       "       [<tk 今 >],\n",
       "       [<tk 。 >],\n",
       "       [<tk 孕 >],\n",
       "       [<tk 早 >],\n",
       "       [<tk 期 >],\n",
       "       [<tk 无 >],\n",
       "       [<tk 感 >],\n",
       "       [<tk 冒 >],\n",
       "       [<tk 、 >],\n",
       "       [<tk 发 >],\n",
       "       [<tk 热 >],\n",
       "       [<tk 、 >],\n",
       "       [<tk 服 >],\n",
       "       [<tk 用 >],\n",
       "       [<tk 药 >],\n",
       "       [<tk 物 >],\n",
       "       [<tk 病 >],\n",
       "       [<tk 史 >],\n",
       "       [<tk , >],\n",
       "       [<tk 孕 >],\n",
       "       [<tk 中 >],\n",
       "       [<tk 期 >],\n",
       "       [<tk 无 >],\n",
       "       [<tk 头 >],\n",
       "       [<tk 痛 >],\n",
       "       [<tk 、 >],\n",
       "       [<tk 头 >],\n",
       "       [<tk 晕 >],\n",
       "       [<tk , >],\n",
       "       [<tk 无 >],\n",
       "       [<tk 眼 >],\n",
       "       [<tk 花 >],\n",
       "       [<tk 、 >],\n",
       "       [<tk 视 >],\n",
       "       [<tk 物 >],\n",
       "       [<tk 模 >],\n",
       "       [<tk 糊 >],\n",
       "       [<tk , >],\n",
       "       [<tk 无 >],\n",
       "       [<tk 抽 >],\n",
       "       [<tk 搐 >],\n",
       "       [<tk 、 >],\n",
       "       [<tk 晕 >],\n",
       "       [<tk 厥 >],\n",
       "       [<tk , >],\n",
       "       [<tk 无 >],\n",
       "       [<tk 水 >],\n",
       "       [<tk 肿 >],\n",
       "       [<tk , >],\n",
       "       [<tk 无 >],\n",
       "       [<tk 胸 >],\n",
       "       [<tk 闷 >],\n",
       "       [<tk 、 >],\n",
       "       [<tk 气 >],\n",
       "       [<tk 促 >],\n",
       "       [<tk 等 >],\n",
       "       [<tk 不 >],\n",
       "       [<tk 适 >],\n",
       "       [<tk , >],\n",
       "       [<tk 孕 >],\n",
       "       [<tk 期 >],\n",
       "       [<tk 否 >],\n",
       "       [<tk 认 >],\n",
       "       [<tk 接 >],\n",
       "       [<tk 触 >],\n",
       "       [<tk 有 >],\n",
       "       [<tk 毒 >],\n",
       "       [<tk 、 >],\n",
       "       [<tk 有 >],\n",
       "       [<tk 害 >],\n",
       "       [<tk 及 >],\n",
       "       [<tk 放 >],\n",
       "       [<tk 射 >],\n",
       "       [<tk 性 >],\n",
       "       [<tk 物 >],\n",
       "       [<tk 质 >],\n",
       "       [<tk 。 >],\n",
       "       [<tk 孕 >],\n",
       "       [<tk 1 >],\n",
       "       [<tk 2 >],\n",
       "       [<tk 周 >],\n",
       "       [<tk 我 >],\n",
       "       [<tk 院 >],\n",
       "       [<tk 建 >],\n",
       "       [<tk 册 >],\n",
       "       [<tk , >],\n",
       "       [<tk 孕 >],\n",
       "       [<tk 期 >],\n",
       "       [<tk 产 >],\n",
       "       [<tk 检 >],\n",
       "       [<tk 6 >],\n",
       "       [<tk 次 >],\n",
       "       [<tk , >],\n",
       "       [<tk 孕 >],\n",
       "       [<tk 妇 >],\n",
       "       [<tk 因 >],\n",
       "       [<tk 高 >],\n",
       "       [<tk 龄 >],\n",
       "       [<tk 建 >],\n",
       "       [<tk 议 >],\n",
       "       [<tk 产 >],\n",
       "       [<tk 前 >],\n",
       "       [<tk 诊 >],\n",
       "       [<tk 断 >],\n",
       "       [<tk , >],\n",
       "       [<tk 患 >],\n",
       "       [<tk 者 >],\n",
       "       [<tk 拒 >],\n",
       "       [<tk 绝 >],\n",
       "       [<tk , >],\n",
       "       [<tk 要 >],\n",
       "       [<tk 求 >],\n",
       "       [<tk 行 >],\n",
       "       [<tk 深 >],\n",
       "       [<tk 圳 >],\n",
       "       [<tk 市 >],\n",
       "       [<tk 人 >],\n",
       "       [<tk 民 >],\n",
       "       [<tk 医 >],\n",
       "       [<tk 院 >],\n",
       "       [<tk 无 >],\n",
       "       [<tk 创 >],\n",
       "       [<tk D >],\n",
       "       [<tk N >],\n",
       "       [<tk A >],\n",
       "       [<tk 检 >],\n",
       "       [<tk 测 >],\n",
       "       [<tk 示 >],\n",
       "       [<tk : >],\n",
       "       [<tk 低 >],\n",
       "       [<tk 风 >],\n",
       "       [<tk 险 >],\n",
       "       [<tk 。 >],\n",
       "       [<tk 孕 >],\n",
       "       [<tk 2 >],\n",
       "       [<tk 4 >],\n",
       "       [<tk + >],\n",
       "       [<tk 周 >],\n",
       "       [<tk 行 >],\n",
       "       [<tk O >],\n",
       "       [<tk G >],\n",
       "       [<tk T >],\n",
       "       [<tk T >],\n",
       "       [<tk : >],\n",
       "       [<tk 4 >],\n",
       "       [<tk . >],\n",
       "       [<tk 8 >],\n",
       "       [<tk - >],\n",
       "       [<tk 1 >],\n",
       "       [<tk 0 >],\n",
       "       [<tk . >],\n",
       "       [<tk 6 >],\n",
       "       [<tk - >],\n",
       "       [<tk 7 >],\n",
       "       [<tk . >],\n",
       "       [<tk 9 >],\n",
       "       [<tk m >],\n",
       "       [<tk m >],\n",
       "       [<tk o >],\n",
       "       [<tk l >],\n",
       "       [<tk / >],\n",
       "       [<tk L >],\n",
       "       [<tk , >],\n",
       "       [<tk 无 >],\n",
       "       [<tk 多 >],\n",
       "       [<tk 饮 >],\n",
       "       [<tk 、 >],\n",
       "       [<tk 多 >],\n",
       "       [<tk 食 >],\n",
       "       [<tk 及 >],\n",
       "       [<tk 多 >],\n",
       "       [<tk 尿 >],\n",
       "       [<tk 等 >],\n",
       "       [<tk 不 >],\n",
       "       [<tk 适 >],\n",
       "       [<tk , >],\n",
       "       [<tk 确 >],\n",
       "       [<tk 诊 >],\n",
       "       [<tk 为 >],\n",
       "       [<tk “ >],\n",
       "       [<tk 妊 >],\n",
       "       [<tk 娠 >],\n",
       "       [<tk 期 >],\n",
       "       [<tk 糖 >],\n",
       "       [<tk 尿 >],\n",
       "       [<tk 病 >],\n",
       "       [<tk ” >],\n",
       "       [<tk , >],\n",
       "       [<tk 适 >],\n",
       "       [<tk 当 >],\n",
       "       [<tk 活 >],\n",
       "       [<tk 动 >],\n",
       "       [<tk 及 >],\n",
       "       [<tk 饮 >],\n",
       "       [<tk 食 >],\n",
       "       [<tk 调 >],\n",
       "       [<tk 控 >],\n",
       "       [<tk , >],\n",
       "       [<tk 自 >],\n",
       "       [<tk 行 >],\n",
       "       [<tk 监 >],\n",
       "       [<tk 测 >],\n",
       "       [<tk 血 >],\n",
       "       [<tk 糖 >],\n",
       "       [<tk 控 >],\n",
       "       [<tk 制 >],\n",
       "       [<tk 可 >],\n",
       "       [<tk 。 >],\n",
       "       [<tk 孕 >],\n",
       "       [<tk 期 >],\n",
       "       [<tk 无 >],\n",
       "       [<tk 头 >],\n",
       "       [<tk 痛 >],\n",
       "       [<tk 、 >],\n",
       "       [<tk 头 >],\n",
       "       [<tk 晕 >],\n",
       "       [<tk , >],\n",
       "       [<tk 无 >],\n",
       "       [<tk 眼 >],\n",
       "       [<tk 花 >],\n",
       "       [<tk 、 >],\n",
       "       [<tk 视 >],\n",
       "       [<tk 物 >],\n",
       "       [<tk 模 >],\n",
       "       [<tk 糊 >],\n",
       "       [<tk , >],\n",
       "       [<tk 无 >],\n",
       "       [<tk 抽 >],\n",
       "       [<tk 搐 >],\n",
       "       [<tk 、 >],\n",
       "       [<tk 晕 >],\n",
       "       [<tk 厥 >],\n",
       "       [<tk , >],\n",
       "       [<tk 无 >],\n",
       "       [<tk 水 >],\n",
       "       [<tk 肿 >],\n",
       "       [<tk , >],\n",
       "       [<tk 无 >],\n",
       "       [<tk 胸 >],\n",
       "       [<tk 闷 >],\n",
       "       [<tk 、 >],\n",
       "       [<tk 气 >],\n",
       "       [<tk 促 >],\n",
       "       [<tk 等 >],\n",
       "       [<tk 不 >],\n",
       "       [<tk 适 >],\n",
       "       [<tk ; >],\n",
       "       [<tk 无 >],\n",
       "       [<tk 多 >],\n",
       "       [<tk 饮 >],\n",
       "       [<tk 、 >],\n",
       "       [<tk 多 >],\n",
       "       [<tk 食 >],\n",
       "       [<tk 、 >],\n",
       "       [<tk 多 >],\n",
       "       [<tk 尿 >],\n",
       "       [<tk 等 >],\n",
       "       [<tk 不 >],\n",
       "       [<tk 适 >],\n",
       "       [<tk 。 >],\n",
       "       [<tk 今 >],\n",
       "       [<tk 孕 >],\n",
       "       [<tk 2 >],\n",
       "       [<tk 6 >],\n",
       "       [<tk + >],\n",
       "       [<tk 6 >],\n",
       "       [<tk 周 >],\n",
       "       [<tk , >],\n",
       "       [<tk 于 >],\n",
       "       [<tk 1 >],\n",
       "       [<tk 6 >],\n",
       "       [<tk : >],\n",
       "       [<tk 0 >],\n",
       "       [<tk 0 >],\n",
       "       [<tk 无 >],\n",
       "       [<tk 明 >],\n",
       "       [<tk 显 >],\n",
       "       [<tk 出 >],\n",
       "       [<tk 现 >],\n",
       "       [<tk 阴 >],\n",
       "       [<tk 道 >],\n",
       "       [<tk 少 >],\n",
       "       [<tk 量 >],\n",
       "       [<tk 流 >],\n",
       "       [<tk 血 >],\n",
       "       [<tk , >],\n",
       "       [<tk 伴 >],\n",
       "       [<tk 腰 >],\n",
       "       [<tk 酸 >],\n",
       "       [<tk , >],\n",
       "       [<tk 无 >],\n",
       "       [<tk 腹 >],\n",
       "       [<tk 痛 >],\n",
       "       [<tk , >],\n",
       "       [<tk 无 >],\n",
       "       [<tk 阴 >],\n",
       "       [<tk 道 >],\n",
       "       [<tk 流 >],\n",
       "       [<tk 水 >],\n",
       "       [<tk , >],\n",
       "       [<tk 遂 >],\n",
       "       [<tk 来 >],\n",
       "       [<tk 我 >],\n",
       "       [<tk 院 >],\n",
       "       [<tk 就 >],\n",
       "       [<tk 诊 >],\n",
       "       [<tk , >],\n",
       "       [<tk 门 >],\n",
       "       [<tk 诊 >],\n",
       "       [<tk 拟 >],\n",
       "       [<tk “ >],\n",
       "       [<tk 晚 >],\n",
       "       [<tk 期 >],\n",
       "       [<tk 难 >],\n",
       "       [<tk 免 >],\n",
       "       [<tk 流 >],\n",
       "       [<tk 产 >],\n",
       "       [<tk ” >],\n",
       "       [<tk 收 >],\n",
       "       [<tk 入 >],\n",
       "       [<tk 院 >],\n",
       "       [<tk 。 >],\n",
       "       [<tk 患 >],\n",
       "       [<tk 者 >],\n",
       "       [<tk 近 >],\n",
       "       [<tk 期 >],\n",
       "       [<tk 无 >],\n",
       "       [<tk 畏 >],\n",
       "       [<tk 寒 >],\n",
       "       [<tk 、 >],\n",
       "       [<tk 发 >],\n",
       "       [<tk 热 >],\n",
       "       [<tk , >],\n",
       "       [<tk 饮 >],\n",
       "       [<tk 食 >],\n",
       "       [<tk 、 >],\n",
       "       [<tk 睡 >],\n",
       "       [<tk 眠 >],\n",
       "       [<tk 、 >],\n",
       "       [<tk 精 >],\n",
       "       [<tk 神 >],\n",
       "       [<tk 好 >],\n",
       "       [<tk , >],\n",
       "       [<tk 二 >],\n",
       "       [<tk 便 >],\n",
       "       [<tk 正 >],\n",
       "       [<tk 常 >],\n",
       "       [<tk 。 >],\n",
       "       [<tk 现 >],\n",
       "       [<tk 病 >],\n",
       "       [<tk 史 >],\n",
       "       [<tk : >],\n",
       "       [<tk 患 >],\n",
       "       [<tk 者 >],\n",
       "       [<tk 孕 >],\n",
       "       [<tk 2 >],\n",
       "       [<tk 产 >],\n",
       "       [<tk 1 >],\n",
       "       [<tk , >],\n",
       "       [<tk 平 >],\n",
       "       [<tk 素 >],\n",
       "       [<tk 月 >],\n",
       "       [<tk 经 >],\n",
       "       [<tk 规 >],\n",
       "       [<tk 律 >],\n",
       "       [<tk , >],\n",
       "       [<tk 末 >],\n",
       "       [<tk 次 >],\n",
       "       [<tk 月 >],\n",
       "       [<tk 经 >],\n",
       "       [<tk 2 >],\n",
       "       [<tk 0 >],\n",
       "       [<tk 1 >],\n",
       "       [<tk 7 >],\n",
       "       [<tk 年 >],\n",
       "       [<tk 4 >],\n",
       "       [<tk 月 >],\n",
       "       [<tk 5 >],\n",
       "       [<tk 日 >],\n",
       "       [<tk , >],\n",
       "       [<tk 停 >],\n",
       "       [<tk 经 >],\n",
       "       [<tk 4 >],\n",
       "       [<tk 0 >],\n",
       "       [<tk + >],\n",
       "       [<tk 天 >],\n",
       "       [<tk 查 >],\n",
       "       [<tk 尿 >],\n",
       "       [<tk 妊 >],\n",
       "       [<tk 娠 >],\n",
       "       [<tk 试 >],\n",
       "       [<tk 验 >],\n",
       "       [<tk ( >],\n",
       "       [<tk + >],\n",
       "       [<tk ) >],\n",
       "       [<tk , >],\n",
       "       [<tk 6 >],\n",
       "       [<tk 月 >],\n",
       "       [<tk 2 >],\n",
       "       [<tk 8 >],\n",
       "       [<tk 日 >],\n",
       "       [<tk 查 >],\n",
       "       [<tk B >],\n",
       "       [<tk 超 >],\n",
       "       [<tk 示 >],\n",
       "       [<tk : >],\n",
       "       [<tk 宫 >],\n",
       "       [<tk 内 >],\n",
       "       [<tk 妊 >],\n",
       "       [<tk 娠 >],\n",
       "       [<tk 单 >],\n",
       "       [<tk 活 >],\n",
       "       [<tk 胎 >],\n",
       "       [<tk , >],\n",
       "       [<tk 孕 >],\n",
       "       [<tk 约 >],\n",
       "       [<tk 1 >],\n",
       "       [<tk 2 >],\n",
       "       [<tk 周 >],\n",
       "       [<tk 6 >],\n",
       "       [<tk 天 >],\n",
       "       [<tk 大 >],\n",
       "       [<tk 小 >],\n",
       "       [<tk , >],\n",
       "       [<tk 比 >],\n",
       "       [<tk 停 >],\n",
       "       [<tk 经 >],\n",
       "       [<tk 时 >],\n",
       "       [<tk 间 >],\n",
       "       [<tk 大 >],\n",
       "       [<tk 1 >],\n",
       "       [<tk 周 >],\n",
       "       [<tk , >],\n",
       "       [<tk 据 >],\n",
       "       [<tk 此 >],\n",
       "       [<tk 推 >],\n",
       "       [<tk 测 >],\n",
       "       [<tk 预 >],\n",
       "       [<tk 产 >],\n",
       "       [<tk 期 >],\n",
       "       [<tk 2 >],\n",
       "       [<tk 0 >],\n",
       "       [<tk 1 >],\n",
       "       [<tk 8 >],\n",
       "       [<tk 年 >],\n",
       "       [<tk 1 >],\n",
       "       [<tk 月 >],\n",
       "       [<tk 5 >],\n",
       "       [<tk 日 >],\n",
       "       [<tk 。 >],\n",
       "       [<tk 停 >],\n",
       "       [<tk 经 >],\n",
       "       [<tk 4 >],\n",
       "       [<tk 0 >],\n",
       "       [<tk 余 >],\n",
       "       [<tk 天 >],\n",
       "       [<tk 有 >],\n",
       "       [<tk 恶 >],\n",
       "       [<tk 心 >],\n",
       "       [<tk 、 >],\n",
       "       [<tk 食 >],\n",
       "       [<tk 欲 >],\n",
       "       [<tk 不 >],\n",
       "       [<tk 振 >],\n",
       "       [<tk 、 >],\n",
       "       [<tk 晨 >],\n",
       "       [<tk 起 >],\n",
       "       [<tk 呕 >],\n",
       "       [<tk 吐 >],\n",
       "       [<tk 等 >],\n",
       "       [<tk 早 >],\n",
       "       [<tk 孕 >],\n",
       "       [<tk 反 >],\n",
       "       [<tk 应 >],\n",
       "       [<tk , >],\n",
       "       [<tk 孕 >],\n",
       "       [<tk 3 >],\n",
       "       [<tk + >],\n",
       "       [<tk 月 >],\n",
       "       [<tk 自 >],\n",
       "       [<tk 行 >],\n",
       "       [<tk 消 >],\n",
       "       [<tk 失 >],\n",
       "       [<tk , >],\n",
       "       [<tk 孕 >],\n",
       "       [<tk 4 >],\n",
       "       [<tk + >],\n",
       "       [<tk 月 >],\n",
       "       [<tk 自 >],\n",
       "       [<tk 觉 >],\n",
       "       [<tk 胎 >],\n",
       "       [<tk 动 >],\n",
       "       [<tk 至 >],\n",
       "       [<tk 今 >],\n",
       "       [<tk 。 >],\n",
       "       [<tk 孕 >],\n",
       "       [<tk 早 >],\n",
       "       [<tk 期 >],\n",
       "       [<tk 无 >]], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<tk 尤 >, <tk 甚 >, <tk , >, ..., <tk , >, <tk 口 >, <tk 酸 >],\n",
       "       [<tk 甚 >, <tk , >, <tk 伴 >, ..., <tk 口 >, <tk 干 >, <tk 、 >],\n",
       "       [<tk , >, <tk 伴 >, <tk 反 >, ..., <tk 干 >, <tk 、 >, <tk 烧 >],\n",
       "       ...,\n",
       "       [<tk 动 >, <tk 至 >, <tk 今 >, ..., <tk 冒 >, <tk 、 >, <tk 早 >],\n",
       "       [<tk 至 >, <tk 今 >, <tk 。 >, ..., <tk 、 >, <tk 发 >, <tk 期 >],\n",
       "       [<tk 今 >, <tk 。 >, <tk 孕 >, ..., <tk 发 >, <tk 热 >, <tk 无 >]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
