{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Init NLPText\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from pprint import pprint\n",
    "from nlptext.base import BasicObject\n",
    "\n",
    "########### ResumeNER ###########\n",
    "CORPUSPath = 'dataset/ResumeNER/'\n",
    "corpusFileIden = '.bmes'\n",
    "textType   = 'block'\n",
    "Text2SentMethod  = 're'\n",
    "Sent2TokenMethod = 'iter'\n",
    "TOKENLevel = 'char'\n",
    "anno = 'embed'\n",
    "annoKW = {}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "MaxTextIdx = False\n",
    "\n",
    "\n",
    "BasicObject.INIT(CORPUSPath, corpusFileIden, textType, \n",
    "                 Text2SentMethod, Sent2TokenMethod, TOKENLevel, \n",
    "                 anno, annoKW, MaxTextIdx)\n",
    "\n",
    "from nlptext.corpus import Corpus\n",
    "corpus = Corpus()\n",
    "# corpus.IdxFolderStartEnd\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Corpus Channel Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "\n",
    "from nlptext.corpus import Corpus\n",
    "\n",
    "\n",
    "corpus = Corpus()\n",
    "print(corpus.TokenNum_Dir)\n",
    "\n",
    "\n",
    "#if os.path.isdir(corpus.Channel_Dir):\n",
    "#    shutil.rmtree(corpus.Channel_Dir)\n",
    "\n",
    "CHANNEL_SETTINGS_TEMPLATE = {\n",
    "    \n",
    "    # CTX_IND\n",
    "    'token':  {'use':         True,\n",
    "               'Max_Ngram':   1},\n",
    "    \n",
    "    'char':   {'use':         True,\n",
    "               'Max_Ngram':   1,\n",
    "               'end_grain':   False},\n",
    "    \n",
    "    'basic':  {'use':         True,\n",
    "               'Max_Ngram':   1,\n",
    "               'end_grain':   False},\n",
    "        \n",
    "    'medical':{'use':         True,\n",
    "               'Max_Ngram':   1,\n",
    "               'end_grain':   False},\n",
    "    \n",
    "    'radical':{'use':         True,\n",
    "               'Max_Ngram':   1,\n",
    "               'end_grain':   False},\n",
    "    \n",
    "    'subcomp':{'use':         True,\n",
    "               'Max_Ngram':   3,\n",
    "               'end_grain':   False},\n",
    "\n",
    "    'stroke': {'use':         True,\n",
    "               'Max_Ngram':   5,\n",
    "               'end_grain':   False},\n",
    "    \n",
    "    # CTX_DEP\n",
    "    'pos':    {'use':         True,\n",
    "               'Max_Ngram':   1,\n",
    "               'end_grain':   False,\n",
    "               'tagScheme':   'BIO',\n",
    "               'tagSet':      None},\n",
    "    \n",
    "    # ANNO\n",
    "    'annoR':  {'use':         True,\n",
    "               'Max_Ngram':   1,\n",
    "               'end_grain':   False,\n",
    "               'tagScheme':   'BIO',\n",
    "               'tagSet':      None},\n",
    "    \n",
    "    \n",
    "    'annoE': {'use':         True,\n",
    "              'Max_Ngram':   1,\n",
    "              'end_grain':   False,\n",
    "              'tagScheme':   'BIO',\n",
    "              'tagSet':      None},\n",
    "}\n",
    "\n",
    "\n",
    "BasicObject.BUILD_GRAIN_UNI_AND_LOOKUP(CHANNEL_SETTINGS_TEMPLATE)\n",
    "\n",
    "\n",
    "# TODO: pretty print the result.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. getTensor Test\n",
    "\n",
    "## 3.1 Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tk = corpus.Tokens[12]\n",
    "tk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNK_ID = 3\n",
    "\n",
    "Max_Ngram = 1\n",
    "channel = 'token'\n",
    "tagScheme = 'BIO'\n",
    "end_grain = False\n",
    "\n",
    "LGU, DGU = tk.getGrainUnique(channel, Max_Ngram = Max_Ngram, end_grain = end_grain, tagScheme = tagScheme)\n",
    "\n",
    "info = [DGU.get(i,UNK_ID ) for i in tk.getChannelGrain(channel, \n",
    "                                                             Max_Ngram = Max_Ngram, \n",
    "                                                             end_grain = end_grain,\n",
    "                                                             tagScheme = tagScheme)]\n",
    "\n",
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Max_Ngram = 5\n",
    "channel = 'stroke'\n",
    "tagScheme = 'BIO'\n",
    "end_grain = False\n",
    "\n",
    "LGU, DGU = tk.getGrainUnique(channel, Max_Ngram = Max_Ngram, end_grain = end_grain, tagScheme = tagScheme)\n",
    "\n",
    "info = [DGU.get(i,UNK_ID ) for i in tk.getChannelGrain(channel, \n",
    "                                                             Max_Ngram = Max_Ngram, \n",
    "                                                             end_grain = end_grain,\n",
    "                                                             tagScheme = tagScheme)]\n",
    "\n",
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('stroke')\n",
    "info, leng = tk.getGrainTensor('stroke', Max_Ngram=5)\n",
    "print(info)\n",
    "print(leng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print()\n",
    "print('pos')\n",
    "info, leng = tk.getGrainTensor('pos', Max_Ngram=1)\n",
    "print(info)\n",
    "print(leng)\n",
    "\n",
    "print()\n",
    "print('annoE')\n",
    "info, leng = tk.getGrainTensor('annoE', Max_Ngram=1)\n",
    "print(info)\n",
    "print(leng)\n",
    "\n",
    "\n",
    "print()\n",
    "print('subcomp')\n",
    "info, leng = tk.getGrainTensor('subcomp', Max_Ngram=3)\n",
    "print(info)\n",
    "print(leng)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = tk.Sentence\n",
    "print(st)\n",
    "st.sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "channel = 'annoE'\n",
    "\n",
    "info, leng, leng_s, maxGr, maxTk = st.getGrainTensor(channel)\n",
    "print(info)\n",
    "print(leng)\n",
    "print(leng_s)\n",
    "print(maxGr)\n",
    "print(maxTk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "channel = 'pos'\n",
    "\n",
    "info, leng, leng_s, maxGr, maxTk= st.getGrainTensor(channel)\n",
    "print(info)\n",
    "print(leng)\n",
    "print(leng_s)\n",
    "print(maxGr)\n",
    "print(maxTk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel = 'stroke'\n",
    "\n",
    "info, leng, leng_s, maxGr, maxTk = st.getGrainTensor(channel, Max_Ngram=5, useStartEnd=True)\n",
    "print(info)\n",
    "print(leng)\n",
    "print(leng_s)\n",
    "print(maxGr)\n",
    "print(maxTk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlptext.sentence import Sentence\n",
    "\n",
    "st = Sentence(sentence = '1.咳嗽查因:咳嗽变异性哮喘?迁延性支气管炎?')\n",
    "print(st.sentence)\n",
    "print(st)\n",
    "\n",
    "\n",
    "channel = 'stroke'\n",
    "\n",
    "info, leng, leng_s, maxGr, maxTk  = st.getGrainTensor(channel)\n",
    "print(info)\n",
    "print(leng)\n",
    "print(leng_s)\n",
    "print(maxGr)\n",
    "print(maxTk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel = 'stroke'\n",
    "info, leng, leng_s, maxGr, maxTk  = st.getGrainTensor(channel, Max_Ngram=2, useStartEnd=True)\n",
    "print(info)\n",
    "print(leng)\n",
    "print(leng_s)\n",
    "print(maxGr)\n",
    "print(maxTk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
